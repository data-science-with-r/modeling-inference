{
  "hash": "06bb647c0425a74229432e5f2b3f23a1",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Quantifying Uncertanity\nsubtitle: \"{{< fa book-open >}} Modeling Inference <br>{{< fa book >}} Data Science with R\"\nformat: live-html\nengine: knitr\nbibliography: references.bib\nwebr:\n  packages: \n    - tidyverse\n    - tidymodels\n    # - faraway\n    #- scales\n    #- ggridges\n    # - kableExtra\n  cell-options:\n    autorun: false\n---\n\n\n<!-- begin: webr fodder -->\n\n::: {.cell}\n\n:::\n\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\n#| echo: false\n#| output: false\n\ngilbert <- \n  tibble(\n    outcome = c(rep(\"died\", 74), \n                rep(\"no-death\", 1567)),\n    working = c(rep(\"gilbert\", 40), \n                rep(\"no-gilbert\", 34), \n                rep(\"gilbert\", 217), \n                rep(\"no-gilbert\", 1350)))\n\n```\n:::\n\n\n<!-- end: webr fodder -->\n\n# Getting Started\n\nProgramming exercises are designed to provide an opportunity for you to put what you learn in the videos and readings. These exercises feature interactive code cells which allow you to write, edit, and run R code without leaving your browser.\n\nWhen the ▶️ Run Code button turns to a solid color (with no flashing bubble indicating that the document is still loading), you can interact with the code cells!\n\n## Packages\n\nWe’ll use the **tidyverse** and **tidymodels** for this programming exercise. These are already installed for you to use!\n\n## Motivation and data set information\n\nFor several years in the 1990s, Kristen Gilbert worked as a nurse in the intensive care unit (ICU) of the Veterans Administration Hospital in Northampton, Massachusetts. Over the course of her time there, other nurses came to suspect that she was killing patients by injecting them with the heart stimulant epinephrine. Gilbert was eventually arrested and charged with these murders. Part of the evidence presented against Gilbert at her murder trial was a statistical analysis of 1,641 randomly selected eight-hour shifts during the time Gilbert worked in the ICU. For each of these shifts, researchers recorded two variables: whether Gilbert worked on the shift and whether at least one patient died during the shift.\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\nThe data set you will be working with is called `gilbert`. The data are already pre-loaded for you! Simply run the code below to get started. The data key can be seen below.\n\n\n::: {.cell}\n```{webr}\ngilbert\n```\n:::\n\n\n| Variable | Description                                                                                       |\n|----------|---------------------------------------------------------------------------------------------------|\n| outcome  | patient died (died) or a patient did not die (no-death)                                           |\n| working  | Gilbert was working on this shift (gilbert) or Gilbert was not working on this shift (no-gilbert) |\n\n\n#### Exploratory data analysis \n\nBefore we get into the inference portion of this activity, let's think about and explore our data. \n\n::: exercise\n\nThought exercise: What are the observational units? Are our variables categorical or quantitative?\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\nOur observational units are whom or what we take the data off of. In this case, data are collected from individual shifts. Both variables that we are working with are categorial variables.\n:::\n\nNow that we know what types of variables we are working with, let's calculate some summary statistics. \n\n\n::: exercise\nCreate a summary table using `summarize()` and `group_by()` to display the count for each combination of `outcome` and `working` level. What would our sample statistic be? \n:::\n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\ngilbert |>\n  group_by(outcome, working) |>\n  summarize(n = n())\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'outcome'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 3\n# Groups:   outcome [2]\n  outcome  working        n\n  <chr>    <chr>      <int>\n1 died     gilbert       40\n2 died     no-gilbert    34\n3 no-death gilbert      217\n4 no-death no-gilbert  1350\n```\n\n\n:::\n:::\n\n\nOur sample statistic would be $\\widehat{p_\\text{no-gilbert}} - \\widehat{p_\\text{gilbert}}$ = $\\frac{34}{1384} - \\frac{40}{257} = -.13$\n:::\n\n::: exercise\nNow, create a proper data visualization to help explore these data. Comment on a patterns you observe with these data. Hint: In the appropriate `geom`, use `position = \"fill` to create a visualization that is easier to read when we have differing sample sizes. Include appropriate labels. What pattern do you reconize?\n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilbert |>\n  ggplot(\n    aes(x = working, fill = outcome)\n  ) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"Murderous Nurse Data\",\n       y = \"conditional proportion\")\n```\n\n::: {.cell-output-display}\n![](nurse_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nBased on the visualization, it appears that their were significantly more outcomes of died vs no-death when Gilbert was on shift vs not on the shift.\n:::\n\n## Inference: Hypothesis Testing \n\nAs stated above, part of the evidence presented against Gilbert at her murder trial was a statistical analysis of 1,641 randomly selected eight-hour shifts during the time Gilbert worked in the ICU. We are going to conduct re-create the hypothesis test presented, via simulation techniques. \n\n::: exercise \n\nThought exercise: Below, think about what the null and alternative hypothesis would be for this scenario. Think about this both in proper notation, and in words.\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\nOur null hypothesis is:\n\n$H_o: \\pi_\\text{no-gilbert} - \\pi_\\text{gilbert} = 0$\n\nIn words, this is the true proportion of patients who died during shifts where Gilbert was not working is the same as when she was working. \n\nOur alternative hypothesis is: \n\n$H_a:\\pi_\\text{no-gilbert} - \\pi_\\text{gilbert} < 0$\n\nIn words, this is the true proportion of patients who died during shifts where Gilbert was not working is lower than when she was working. \n\nWe choose lower (<), because of the order of subtraction, and that we are trying to see if more people died while she was working vs not.\n:::\n\n#### Building a Distribution \n\n::: exercise\n\nLet’s use simulation-based methods to conduct the hypothesis test specified above. We’ll start by generating the null distribution. First, let’s start by explicitly calculating the sample size for each group. These values will be important for simulating our sampling distribution under the assumption of the null hypothesis.\n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngilbert |>\n  group_by(working) |>\n  summarize(count = n())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 2\n  working    count\n  <chr>      <int>\n1 gilbert      257\n2 no-gilbert  1384\n```\n\n\n:::\n:::\n\n:::\n\nThe steps to simulate our sampling distribution under the assumption of the null hypothesis are as follows: \n\n-- Permute or shuffle all observations together, regardless their value of work (grouping variable)\n\n-- Randomly distribute observations into two new groups of size n1 = 257 and n2 = 1384 \n\n-- Summarize the data for each group \n\n-- Subtract \n\n... and we do the entire process above many many times.\n\n::: exercise\n\nThought exercise: Why are we shuffling all observations together? \n\nWhy do we randomly distribute back into new groups of the same size as our original data?\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\nHypothesis tests are conducted under the assumption of the null hypothesis. Our null hypothesis is that the groups \"don't matter\". To simulate data under this assumption from our observed data, we remove the group label, and permute observations back out into two new groups, regardless of their group label from the original data. \n\nWe distribute these observations back into groups of the same size as before, because we want our sampling distribution to be comparable to our original statistic. The goal of hypothesis testing is to see how unlikely our statistic is, under the assumption of the null hypothesis. It's not a fair comparison to our original statistic if the sample sizes for each group are different. \n:::\n\nNow, let's use R to simulate the process discussed above. Save your permutated values as the object `null_dist`. We plot this object later.\n\n::: exercise\n\n\n::: {.cell}\n```{webr}\nset.seed(12345) # so you have reproducible results\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Hint\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist <- gilbert |>\n  specify(response = ____, explanatory = ____, success = \"___\") |> # specify your variables here, and what you are taking the proportion of\n  hypothesize(null = \"independence\") |> # this says we want to do a hypothesis test for independence\n  generate(reps = ____, type = \"permute\") |> # this says we are going to use permutation. Put an appropriate number of reps in\n  calculate(stat = \"_____\", order = c(\"_____\", \"_____\")) # specify our statistic and the order of subtraction here\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345)\n\nnull_dist <- gilbert |>\n  specify(response = outcome, explanatory = working, success = \"died\") |> # specify your variables here\n  hypothesize(null = \"independence\") |> # this says we want to do a hypothesis test for independence\n  generate(reps = 1000, type = \"permute\") |> # this says we are going to use permutation. Put an appropriate number of reps in\n  calculate(stat = \"diff in props\", order = c(\"no-gilbert\", \"gilbert\")) # specify our statistic and the order of subtraction here\n\ntibble(null_dist)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1,000 × 2\n   replicate     stat\n       <int>    <dbl>\n 1         1 -0.00189\n 2         2  0.00272\n 3         3 -0.0111 \n 4         4  0.0119 \n 5         5  0.00733\n 6         6  0.0166 \n 7         7  0.0166 \n 8         8 -0.00189\n 9         9 -0.00189\n10        10  0.0258 \n# ℹ 990 more rows\n```\n\n\n:::\n:::\n\n\nYou have now created 1000 simulated difference in proportions under the assumption of $H_o: \\pi_\\text{no-gilbert} - \\pi_\\text{gilbert} = 0$. \n:::\n\nLet's now plot your simulated difference in proportions, and calculate our p-value! To do so, we are going to use the following code: \n\n```\nvisualize(_____) +\n  shade_p_value(____, direction = \"____\")\n```\n\nThe first argument in the `visualize()` function is your R object of simulated proportions. This is why we saved these proportions as `null_dist`. The first argument in the `shade_p-value()` function is our statistic. The original statistic we calculated (-.13). Lastly, we need to specify the direction we shade from our statistic. This function will take the arguments \"less\", \"left\", \"greater\", \"right\", \"two-sided\", \"both\", \"two_sided\", \"two sided\", or \"two.sided\".\n::: exercise\nA p-value, in this context, is the probability of observing -.13, or something even **lower**, given $H_o: \\pi_\\text{no-gilbert} - \\pi_\\text{gilbert} = 0$. Lower comes from our alternative hypothesis sign (i.e., our research question). Use this information to plot our our simulated sampling distribution and shade the appropriate area for our p-value below.\n\nWhat do we notice? Is our p-value large or small? \n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nvisualize(null_dist) +\n  shade_p_value(-.13, direction = \"less\")\n```\n\n::: {.cell-output-display}\n![](nurse_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nWe notice that, out of 1000 samples generated under the assumption of the null hypothesis, we observed 0 samples as small, or even smaller than -.13. This would indicate that our p-value is very very small.\n:::\n\n::: exercise\nBased on our simulated hypothesis test, we calculated an extremely small p-value. What does this mean for our null and alternative hypothesis? What can we conclude. Assume you are comparing your p-value vs a significance level of $\\alpha = 0.05$\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\nWith an extremely small p-value, at a 5% significance level, we would reject the null hypothesis, and have strong evidence to conclude that the true proportion of patient outcomes that resulted in no death were lower when Gilbert was not working vs when she was working.\n:::\n\n::: exercise\nThought exercise: How would we define $\\alpha$ in this context?\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n$\\alpha$ is a threshold we use against our p-value to see if we have enough evidence to reject the null hypothesis. It is also the probability of committing a Type I error. In this context, we have a 5% chance of rejecting the null hypothesis when the null hypothesis was actually true. \n:::\n\n\n## Inference: Confidence Intervals\n\nNow, we are going to estimate $\\pi_\\text{no-gilbert} - \\pi_\\text{gilbert}$. We can do this by conducting a confidence interval! Again, we will use simulation techniques. Let's go through the steps below. \n\nAs a reminder, we **no longer** have a hypothesis to assume true. Our whole goal is to estimate $pi_\\text{no-gilbert} - \\pi_\\text{gilbert}$. At their core, confidence intervals are our \"best guess\" of what $pi_\\text{no-gilbert} - \\pi_\\text{gilbert}$ might be, accompanied by a range of values created through quantifying uncertainty around our \"best guess\". Our best guess is the sample statistic calculated from above: $\\widehat{p_\\text{no-gilbert}} - \\widehat{p_\\text{gilbert}}$ = $\\frac{217}{1567} - \\frac{40}{74} = -.13$. Let's now go through the steps to quantify our uncertainty (build up a sampling distribution).\n\n-- Randomly sample **within each group**  n1 = 257 and n2 = 1384 times, respectively. \n\n-- Summarize the data for each group \n\n-- Subtract \n\n... and we do the entire process above many many times. \n\nThis process is called bootstrap resampling.\n\n::: exercise\n\nThought exercise: Why did we not shuffle the groups together, and instead randomly sample from each group?\n\nWhy do we make sure to randomly sample from each group equal to the sample size as our original groups?\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\nWe want our sampling distribution to be centered at our \"best guess\" of $pi_\\text{no-gilbert} - \\pi_\\text{gilbert}$, which is our statistic calculated to be -.13. To ensure this, we need to keep the integrity of our groups. This includes keeping the sample sizes the same for each group.\n:::\n\nNow, let's use R to simulate the process discussed above. Save your permutated values as the object `boot_dist`. We plot this object later.\n\n\n::: {.cell}\n```{webr}\nset.seed(12345)\n\n```\n:::\n\n\n::: {.callout-tip collapse=\"true\"}\n## Hint\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist <- gilbert |>\n  specify(response = ____, explanatory = ____, success = \"___\") |> # specify your variables here, and what you are taking the proportion of) |> # specify your variables here\n  generate(reps = ____, type = \"bootstrap\") |> # this says we are going to use bootstrap techniques. Put an appropriate number of reps in\n  calculate(stat = \"_____\", order = c(\"_____\", \"_____\")) # specify our statistic and the order of subtraction here\n```\n:::\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist <- gilbert |>\n  specify(response = outcome, explanatory = working, success = \"died\") |> # specify your variables here, and what you are taking the proportion of) |> # specify your variables here\n  generate(reps = 1000, type = \"bootstrap\") |> # this says we are going to use bootstrap techniques. Put an appropriate number of reps in\n  calculate(stat = \"diff in props\", order = c(\"no-gilbert\", \"gilbert\")) # specify our statistic and the order of subtraction here\n```\n:::\n\n:::\n\n::: exercise \n\nNow, let's plot our simulated difference in sample proportions below using `geom_histogram()`. Add a vertical line at your statistic using `geom_vline()` to help visualize that the distribution is centered at our statistic.\n:::\n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |>\n  ggplot(\n    aes(x = stat)\n  ) + \n  geom_histogram() +\n  geom_vline(xintercept = -.13) +\n  labs(title = \"simulated sampling distribution\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](nurse_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n\n\nWe can see that our simulated sampling distribution is centered right at -.13, our sample statistic.\n:::\n\n\n\n\nNow, we can use our R object `boot_dist` to calculate different levels of confidence intervals. Recall that, if we want to create a 95% confidence interval, we need to find a lower and upper bound that captures 95% of all simulated difference in proportions. We can do that using the `quantile()` function within `summarize()`. A quantile is a value where a certain percentage of data falls to the left of the specified value. This means: \n\n-- If we want to create a 95% confidence interval, we need to calculate the quantile that excludes 2.5% on the left tail, and the right tail. \n\n-- If we want to create a 90% confidence interval, we need to calculate the quantile that excludes 5% on the left tail, and the right tail. \n\n-- etc. etc. \n\nTake a look at the following demo code: \n\n```\nboot_dist |>\n  summarize(lower = quantile(stat, ____),\n            upper = quantile(stat, ____))\n```\n`boot_dist` is our R object. We use `summarize()` to calculate summary statistics from our `boot_dist` object. The column name `stat` in our `boot_dist` \n\n::: exercise \n\nEdit the following code above the calculate an appropriate 95% confidence interval. Then, think about how this confidence interval should be interpreted. \n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |>\n  summarize(lower = quantile(stat, 0.025),\n            upper = quantile(stat, 0.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n   lower   upper\n   <dbl>   <dbl>\n1 -0.177 -0.0856\n```\n\n\n:::\n:::\n\n\nWe are 95% confident that the true proportion of deaths when Gilbert was not on shift is 0.0850 to 0.180 LOWER than when she was on shift.\n\nNote: Be mindful of order of subtraction.\n:::\n\n::: exercise \n\nWhat happens when the confidence level changes? Look at your distribution, and think critically about what happens to your confidence interval when we go from a 95% confidence interval to an 80% confidence interval. Does the center change? Does the spread change? Use the code chunk below to calculate an 80% confidence interval to check your understanding. \n\n\n::: {.cell}\n```{webr}\n\n```\n:::\n\n\n:::\n\n::: {.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\nboot_dist |>\n  summarize(lower = quantile(stat, 0.10),\n            upper = quantile(stat, 0.90))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 2\n   lower  upper\n   <dbl>  <dbl>\n1 -0.159 -0.102\n```\n\n\n:::\n:::\n\n\nOur confidence interval will ALWAYS be centered at our sample statistic. The center of our distribution does not change. However, as our confidence level decreases, so does the width (as ween from the above code).\n\n:::\n\n## In Summary \n\n-- We can use randomization and bootstrap techniques for statistical inference.\n\n-- When we want to test a population parameter vs a given value, we should think about conducting a hypothesis test. \n\n-- When we want to estimate a population parameter, we should think about creating a confidence interval. \n\n-- Depending on the methodolgy, the simulation process will be different, dictating where our sampling distribution is centered.\n\n",
    "supporting": [
      "nurse_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}