{
  "hash": "596704f70489f9247bfdcb7a5bd4bdaf",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Overfitting and spending your data\"\nformat: revealjs\n---\n\n\n\n# Setup\n\n## Packages\n\n- **tidyverse** for data wrangling and visualization\n- **tidymodels** for modeling\n- **forested** for data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\n```\n:::\n\n\n## Data\n\n-   The U.S. Forest Service maintains machine learning models to predict whether a plot of land is \"forested.\"\n\n-   This classification is important for research, legislation, land management, etc. purposes.\n\n-   Plots are typically remeasured every 10 years.\n\n-   The `forested` dataset contains the most recent measurement per plot.\n\n## Data: `forested`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 7,107 √ó 19\n   forested  year elevation eastness northness roughness\n   <fct>    <dbl>     <dbl>    <dbl>     <dbl>     <dbl>\n 1 Yes       2005       881       90        43        63\n 2 Yes       2005       113      -25        96        30\n 3 No        2005       164      -84        53        13\n 4 Yes       2005       299       93        34         6\n 5 Yes       2005       806       47       -88        35\n 6 Yes       2005       736      -27       -96        53\n 7 Yes       2005       636      -48        87         3\n 8 Yes       2005       224      -65       -75         9\n 9 Yes       2005        52      -62        78        42\n10 Yes       2005      2240      -67       -74        99\n# ‚Ñπ 7,097 more rows\n# ‚Ñπ 13 more variables: tree_no_tree <fct>, dew_temp <dbl>,\n#   precip_annual <dbl>, temp_annual_mean <dbl>,\n#   temp_annual_min <dbl>, temp_annual_max <dbl>,\n#   temp_january_min <dbl>, vapor_min <dbl>,\n#   vapor_max <dbl>, canopy_cover <dbl>, lon <dbl>,\n#   lat <dbl>, land_type <fct>\n```\n\n\n:::\n:::\n\n\n## Data: `forested`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 7,107\nColumns: 19\n$ forested         <fct> Yes, Yes, No, Yes, Yes, Yes, Yes,‚Ä¶\n$ year             <dbl> 2005, 2005, 2005, 2005, 2005, 200‚Ä¶\n$ elevation        <dbl> 881, 113, 164, 299, 806, 736, 636‚Ä¶\n$ eastness         <dbl> 90, -25, -84, 93, 47, -27, -48, -‚Ä¶\n$ northness        <dbl> 43, 96, 53, 34, -88, -96, 87, -75‚Ä¶\n$ roughness        <dbl> 63, 30, 13, 6, 35, 53, 3, 9, 42, ‚Ä¶\n$ tree_no_tree     <fct> Tree, Tree, Tree, No tree, Tree, ‚Ä¶\n$ dew_temp         <dbl> 0.04, 6.40, 6.06, 4.43, 1.06, 1.3‚Ä¶\n$ precip_annual    <dbl> 466, 1710, 1297, 2545, 609, 539, ‚Ä¶\n$ temp_annual_mean <dbl> 6.42, 10.64, 10.07, 9.86, 7.72, 7‚Ä¶\n$ temp_annual_min  <dbl> -8.32, 1.40, 0.19, -1.20, -5.98, ‚Ä¶\n$ temp_annual_max  <dbl> 12.91, 15.84, 14.42, 15.78, 13.84‚Ä¶\n$ temp_january_min <dbl> -0.08, 5.44, 5.72, 3.95, 1.60, 1.‚Ä¶\n$ vapor_min        <dbl> 78, 34, 49, 67, 114, 67, 67, 31, ‚Ä¶\n$ vapor_max        <dbl> 1194, 938, 754, 1164, 1254, 1331,‚Ä¶\n$ canopy_cover     <dbl> 50, 79, 47, 42, 59, 36, 14, 27, 8‚Ä¶\n$ lon              <dbl> -118.6865, -123.0825, -122.3468, ‚Ä¶\n$ lat              <dbl> 48.69537, 47.07991, 48.77132, 45.‚Ä¶\n$ land_type        <fct> Tree, Tree, Tree, Tree, Tree, Tre‚Ä¶\n```\n\n\n:::\n:::\n\n\n## Data: `forested`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"forested\"         \"year\"            \n [3] \"elevation\"        \"eastness\"        \n [5] \"northness\"        \"roughness\"       \n [7] \"tree_no_tree\"     \"dew_temp\"        \n [9] \"precip_annual\"    \"temp_annual_mean\"\n[11] \"temp_annual_min\"  \"temp_annual_max\" \n[13] \"temp_january_min\" \"vapor_min\"       \n[15] \"vapor_max\"        \"canopy_cover\"    \n[17] \"lon\"              \"lat\"             \n[19] \"land_type\"       \n```\n\n\n:::\n:::\n\n\n## Outcome and predictors {.smaller}\n\n-   Outcome: `forested` - Factor, `Yes` or `No`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(forested$forested)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Yes\" \"No\" \n```\n\n\n:::\n:::\n\n\n-   Predictors: 18 remotely-sensed and easily-accessible predictors:\n\n    -   numeric variables based on weather and topography\n\n    -   categorical variables based on classifications from other governmental organizations\n\n## `?forested`\n\n<iframe width=\"900\" height=\"500\" src=\"https://simonpcouch.github.io/forested/reference/forested.html\" title=\"forested\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## Should we include a predictor?\n\nTo determine whether we should include a predictor in a model, we should start by asking:\n\n::: incremental\n-   Is it ethical to use this variable?\n    (Or even legal?)\n\n-   Will this variable be available at prediction time?\n\n-   Does this variable contribute to explainability?\n:::\n\n# Data splitting and spending\n\n## We've been cheating!\n\n::: incremental\n-   So far, we've been using all the data we have for building models.\n    In predictive contexts, this would be considered *cheating*.\n\n-   Evaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you've already seen.\n:::\n\n## Spending your data {.smaller}\n\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n![](images/test-train-split.png){fig-align=\"center\"}\n\n-   The **training set** is used to estimate model parameters.\n\n-   The **test set** is used to find an independent assessment of model performance.\n\n. . .\n\n::: callout-warning\nDo not use, or even peek at, the test set during training.\n:::\n\n## How much to spend?\n\n::: incremental\n-   The more data we spend (use in training), the better estimates we‚Äôll get.\n\n-   Spending too much data in training prevents us from computing a good assessment of predictive performance.\n\n-   Spending too much data in testing prevents us from computing a good estimate of model parameters.\n:::\n\n## The initial split\n\nThe default split is 75% training, 25% testing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(20241112)\nforested_split <- initial_split(forested)\nforested_split\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<Training/Testing/Total>\n<5330/1777/7107>\n```\n\n\n:::\n:::\n\n\n## Setting a seed\n\n::: {.columns}\n::: {.column width=70%}\n::: task\nWhat does `set.seed()` do?\n:::\n:::\n::: {.column}\n:::\n:::\n\n\n::: incremental\n-   To create that split of the data, R generates ‚Äúpseudo-random‚Äù numbers: while they are made to behave like random numbers, their generation is deterministic given a ‚Äúseed‚Äù.\n\n-   This allows us to reproduce results by setting that seed.\n\n-   Which seed you pick doesn‚Äôt matter, as long as you don‚Äôt try a bunch of seeds and pick the one that gives you the best performance.\n:::\n\n## Accessing the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_train <- training(forested_split)\nforested_test <- testing(forested_split)\n```\n:::\n\n\n## The training set\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_train\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5,330 √ó 19\n   forested  year elevation eastness northness roughness\n   <fct>    <dbl>     <dbl>    <dbl>     <dbl>     <dbl>\n 1 Yes       2013       315      -17        98        92\n 2 No        2018       374       93       -34        23\n 3 No        2017       377       44       -89         1\n 4 Yes       2013       541       31       -94       139\n 5 Yes       2017       680       14       -98        20\n 6 Yes       2017      1482       76       -64        43\n 7 No        2020        84       42       -90        12\n 8 Yes       2011       210       34        93        16\n 9 No        2020       766       14        98        20\n10 Yes       2013      1559       98        16        79\n# ‚Ñπ 5,320 more rows\n# ‚Ñπ 13 more variables: tree_no_tree <fct>, dew_temp <dbl>,\n#   precip_annual <dbl>, temp_annual_mean <dbl>,\n#   temp_annual_min <dbl>, temp_annual_max <dbl>,\n#   temp_january_min <dbl>, vapor_min <dbl>,\n#   vapor_max <dbl>, canopy_cover <dbl>, lon <dbl>,\n#   lat <dbl>, land_type <fct>\n```\n\n\n:::\n:::\n\n\n## The testing data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_test\n```\n:::\n\n\nüôà\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(forested_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1777   19\n```\n\n\n:::\n:::\n\n\n# Exploratory data analysis\n\n## Initial questions {.smaller}\n\n-   What‚Äôs the distribution of the outcome, `forested`?\n\n-   What‚Äôs the distribution of numeric variables like `precip_annual`?\n\n-   How does the distribution of forested differ across the categorical and numerical variables?\n\n. . .\n\n::: {.columns}\n::: {.column width=70%}\n::: task\nWhich dataset should we use for the exploration?\nThe entire data `forested`, the training data `forested_train`, or the testing data `forested_test`?\n:::\n:::\n::: {.column}\n:::\n:::\n\n## `forested`\n\n::: {.columns}\n::: {.column width=70%}\n::: task\nWhat‚Äôs the distribution of the outcome, `forested`?\n:::\n:::\n::: {.column}\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforested_train |>\n  count(forested) |>\n  mutate(p = n / sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 √ó 3\n  forested     n     p\n  <fct>    <int> <dbl>\n1 Yes       2917 0.547\n2 No        2413 0.453\n```\n\n\n:::\n:::\n\n\n## `precip_annual`\n\nWhat‚Äôs the distribution of `precip_annual`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(forested_train, aes(x = precip_annual)) +\n  geom_histogram(binwidth = 200)\n```\n\n::: {.cell-output-display}\n![](3-3-overfitting-spending-data_files/figure-revealjs/unnamed-chunk-9-1.png){width=768}\n:::\n:::\n\n\n## `forested` and `precip_annual` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"identity\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](3-3-overfitting-spending-data_files/figure-revealjs/unnamed-chunk-10-1.png){width=768}\n:::\n:::\n\n\n## `forested` and `precip_annual` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|5\"}\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"fill\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](3-3-overfitting-spending-data_files/figure-revealjs/unnamed-chunk-11-1.png){width=768}\n:::\n:::\n\n\n## `forested` and `tree_no_tree` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(forested_train, aes(x = tree_no_tree, fill = forested)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](3-3-overfitting-spending-data_files/figure-revealjs/unnamed-chunk-12-1.png){width=768}\n:::\n:::\n\n\n## `forested` and `lat` / `lon` {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](3-3-overfitting-spending-data_files/figure-revealjs/unnamed-chunk-13-1.png){width=768}\n:::\n:::\n\n\n# Terminology\n\n## Recap: False negative and positive\n\n-   **False negative rate** is the proportion of actual positives that were classified as negatives.\n\n-   **False positive rate** is the proportion of actual negatives that were classified as positives.\n\n## Recap: Sensitivity\n\n**Sensitivity** is the proportion of actual positives that were correctly classified as positive.\n\n-   Also known as **true positive rate** and **recall**\n\n-   Sensitivity = 1 ‚àí False negative rate\n\n-   Useful when false negatives are more \"expensive\" than false positives\n\n## Recap: Specificity\n\n**Specificity** is the proportion of actual negatives that were correctly classified as negative\n\n-   Also known as **true negative rate**\n\n-   Specificity = 1 ‚àí False positive rate\n\n## ROC curve\n\nThe **receiver operating characteristic (ROC) curve** allows to assess the model performance across a range of thresholds.\n\n![](images/roc-curve.png)\n\n## ROC curve {.smaller}\n\n::: {.columns}\n::: {.column width=70%}\n::: task\nWhich corner of the plot indicates the best model performance?\n:::\n:::\n::: {.column}\n:::\n:::\n\n![](images/roc-curve-annotated.png)\n\n# Next steps\n\n## Next steps {.smaller}\n\n::: incremental\n-   Fit models on training data\n\n-   Make predictions on testing data\n\n-   Evaluate predictions on testing data:\n\n    -   Linear models: R-squared, adjusted R-squared, RMSE (root mean squared error), etc.\n    -   Logistic models: False negative and positive rates, AUC (area under the curve), etc.\n\n-   Make decisions based on model predictive performance, validity across various testing/training splits (aka \"cross validation\"), explainability\n:::\n\n. . .\n\n::: callout-note\nWe will only learn about a subset of these in this course, but you can go further into these ideas in other regression and machine learning courses.\n:::\n",
    "supporting": [
      "3-3-overfitting-spending-data_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}