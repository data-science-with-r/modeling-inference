---
title: "Linear model with a numerical predictor"
format: revealjs
---

```{r}
#| label: setup
#| include: false
ggplot2::theme_set(ggplot2::theme_gray(base_size = 16))
```

# Packages and data

## Packages

- **fivethirtyeight** for data
- **tidyverse** for data wrangling and visualization
- **tidymodels** for modeling

```{r}
#| label: load-packages
#| warning: false
library(fivethirtyeight)
library(tidyverse)
library(tidymodels)
```

## Data prep

-   Rename Rotten Tomatoes columns as `critics` and `audience`
-   Rename the dataset as `movie_scores`

```{r}
#| label: data-prep
movie_scores <- fandango |>
  rename(
    critics = rottentomatoes, 
    audience = rottentomatoes_user
  )
```

## Data overview

```{r}
#| label: data-overview
movie_scores |>
  select(critics, audience)
```

## Data visualization

```{r}
#| echo: false
ggplot(movie_scores, aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) + 
  labs(
    x = "Critics Score" , 
    y = "Audience Score"
  )
```

# Regression model

## Regression model

A **regression model** is a function that describes the relationship between the outcome, $Y$, and the predictor, $X$.

$$
\begin{aligned} 
Y &= \color{black}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{black}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{black}{\boldsymbol{\mu_{Y|X}}} + \epsilon 
\end{aligned}
$$

## Regression model

::::: columns
::: {.column width="30%"}
$$
\begin{aligned} 
Y &= \color{#325b74}{\textbf{Model}} + \text{Error} \\[8pt]
&= \color{#325b74}{\mathbf{f(X)}} + \epsilon \\[8pt]
&= \color{#325b74}{\boldsymbol{\mu_{Y|X}}} + \epsilon 
\end{aligned}
$$
:::

::: {.column width="70%"}
```{r}
#| echo: false
#| message: false
m <- lm(audience ~ critics, data = movie_scores)
ggplot(data = movie_scores, 
       mapping = aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) + 
  geom_smooth(method = "lm", color = "#325b74", se = FALSE, linewidth = 1.5) +
  labs(x = "X", y = "Y") +
  theme_minimal() +
  theme(
    axis.text = element_blank(),
    axis.ticks.x = element_blank(), 
    axis.ticks.y = element_blank()
  )
```
:::
:::::

## Simple linear regression {.smaller}

Use **simple linear regression** to model the relationship between a numerical outcome ($Y$) and a single numerical predictor ($X$): $$\Large{Y = \beta_0 + \beta_1 X + \epsilon}$$

::: incremental
-   $\beta_1$: True slope of the relationship between $X$ and $Y$
-   $\beta_0$: True intercept of the relationship between $X$ and $Y$
-   $\epsilon$: Error (residual)
:::

## Simple linear regression

$$
\Large{\hat{Y} = b_0 + b_1 X}
$$

-   $b_1$: Estimated slope of the relationship between $X$ and $Y$
-   $b_0$: Estimated intercept of the relationship between $X$ and $Y$
-   No error term!

## Choosing values for $b_1$ and $b_0$

```{r}
#| echo: false
#| message: false
ggplot(movie_scores, aes(x = critics, y = audience)) +
  geom_point(alpha = 0.4) + 
  geom_abline(intercept = 32.3155, slope = 0.5187, color = "#325b74", linewidth = 1.5) +
  geom_abline(intercept = 25, slope = 0.7, color = "gray") +
  geom_abline(intercept = 21, slope = 0.9, color = "gray") +
  geom_abline(intercept = 35, slope = 0.3, color = "gray") +
  labs(x = "Critics Score", y = "Audience Score")
```

## Residuals

```{r}
#| message: false
#| echo: false
#| fig-align: center
ggplot(movie_scores, aes(x = critics, y = audience)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", color = "#325b74", se = FALSE, linewidth = 1.5) +
  geom_segment(aes(x = critics, xend = critics, y = audience, yend = predict(m)), color = "steel blue") +
  labs(x = "Critics Score", y = "Audience Score") +
  theme(legend.position = "none")
```

$$
\text{residual} = \text{observed} - \text{predicted} = y - \hat{y}
$$

## Least squares line {.smaller}

-   The residual for the $i^{th}$ observation is

$$
e_i = \text{observed} - \text{predicted} = y_i - \hat{y}_i
$$

-   The **sum of squared** residuals is

$$
e^2_1 + e^2_2 + \dots + e^2_n
$$

-   The **least squares line** is the one that **minimizes the sum of squared residuals**

## Fitting a model

```{r}
movies_fit <- linear_reg() |>
  fit(audience ~ critics, data = movie_scores)

tidy(movies_fit)
```

# Interpreting model output

## Interpreting the slope {.smaller}

::: task
The slope of the model for predicting audience score from critics score is 0.519.
Which of the following is the best interpretation of this value?
:::

a.  For every one point increase in the critics score, the audience score goes up by 0.519 points, on average.
b.  For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.
c.  For every one point increase in the critics score, the audience score goes up by 0.519 points.
d.  For every one point increase in the audience score, the critics score goes up by 0.519 points, on average.

## Interpreting slope & intercept

$$
\widehat{\text{audience}} = 32.3 + 0.519 \times \text{critics}
$$

::: incremental
-   **Slope:** For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.
-   **Intercept:** If the critics score is 0 points, we expect the audience score to be 32.3 points.
:::

## Is the intercept meaningful?

âœ… The intercept is meaningful in context of the data if

-   the predictor can feasibly take values equal to or near zero or
-   the predictor has values near zero in the observed data

. . .

ðŸ›‘ Otherwise, it might not be meaningful!

# Putting it altogether

## Least squares regression

The least squares regression line minimizes the sum of squares residuals. It has the following properties:

::: incremental
-   Goes through the center of mass point (the coordinates corresponding to average $X$ and average $Y$): $b_0 = \bar{Y} - b_1~\bar{X}$

-   Slope of the line has the same sign as the correlation coefficient: $b_1 = r \frac{s_Y}{s_X}$

-   Sum of the residuals is zero: $\sum_{i = 1}^n \epsilon_i = 0$

-   Residuals and $X$ values are uncorrelated
:::
