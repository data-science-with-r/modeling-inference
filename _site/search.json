[
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html",
    "title": "Modeling loan interest rates",
    "section": "",
    "text": "Practice modeling with multiple predictors using the data on loan interest rates.\n\nThe dataset is about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\nBefore we use the dataset, we’ll make a few transformations to it.\n\nReview the code below with your neighbor and write a summary of the data transformation pipeline.\n\nAdd response here.\n\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\n\nHere is a glimpse at the data:\n\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#goal",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#goal",
    "title": "Modeling loan interest rates",
    "section": "",
    "text": "Practice modeling with multiple predictors using the data on loan interest rates."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#packages",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#packages",
    "title": "Modeling loan interest rates",
    "section": "",
    "text": "The dataset is about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#data-prep",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#data-prep",
    "title": "Modeling loan interest rates",
    "section": "",
    "text": "Before we use the dataset, we’ll make a few transformations to it.\n\nReview the code below with your neighbor and write a summary of the data transformation pipeline.\n\nAdd response here.\n\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\n\nHere is a glimpse at the data:\n\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#get-to-know-the-data",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#get-to-know-the-data",
    "title": "Modeling loan interest rates",
    "section": "Get to know the data",
    "text": "Get to know the data\n\nWhat is a typical interest rate in this dataset? What are some attributes of a typical loan and a typical borrower. Give yourself no more than 5 minutes for this exploration and share 1-2 findings.\n\n\n# add code here\n\n\n# add code here"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-credit-utilization",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-credit-utilization",
    "title": "Modeling loan interest rates",
    "section": "Interest rate vs. credit utilization",
    "text": "Interest rate vs. credit utilization\n\nFor a regression model for predicting interest rate from credit utilization. Display the summary output.\n\n\n# add code here\n\n\nVisualize the model.\n\n\n# add code here\n\n\nInterpret the intercept and the slope.\n\nIntercept: Add response here.\nSlope: Add response here."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-homeownership",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-homeownership",
    "title": "Modeling loan interest rates",
    "section": "Interest rate vs. homeownership",
    "text": "Interest rate vs. homeownership\n\nFit a regression model for predicting interest rate from homeownership and display the summary output.\n\n\n# add code here\n\n\n\nInterpret each coefficient in context of the problem.\n\nIntercept: Add response here.\n\nSlopes:\n\nAdd response here.\nAdd response here."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-credit-utilization-and-homeownership",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#interest-rate-vs.-credit-utilization-and-homeownership",
    "title": "Modeling loan interest rates",
    "section": "Interest rate vs. credit utilization and homeownership",
    "text": "Interest rate vs. credit utilization and homeownership\nMain effects model\n\nFit a regression model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output.\n\n\n# add code here\n\n\nWrite the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(add~math~text~here\\)\n\nMortgage: \\(add~math~text~here\\)\n\nOwn: \\(add~math~text~here\\)\n\n\n\nHow does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here.\nInteraction effects model\n\nFit a regression model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output.\n\n\n# add code here\n\n\nWrite the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(add~math~text~here\\)\n\nMortgage: \\(add~math~text~here\\)\n\nOwn: \\(add~math~text~here\\)\n\n\n\nHow does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nAdd response here.\nChoosing a model\nRule of thumb: Occam’s Razor - Don’t over-complicate the situation! We prefer the simplest best model.\n\nDisplay model level summary statistics.\n\n\n# add code here\n\n\nWhat is R-squared? What is adjusted R-squared?\n\nAdd response here.\n\nBased on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nAdd response here."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#another-model-to-consider",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates.html#another-model-to-consider",
    "title": "Modeling loan interest rates",
    "section": "Another model to consider",
    "text": "Another model to consider\n\nLet’s add one more model to the variable – issue month. Should we add this variable to the interaction effects model from earlier?\n\n\n# add code here\n\nAdd response here."
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html",
    "title": "Forest classification (Complete)",
    "section": "",
    "text": "In this code along, we will\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the forested package for the data.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\nRemember from the video that the forested dataset contains information on whether a plot is forested (Yes) or not (No) as well as numerical and categorical features of that plot.\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#fit",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#fit",
    "title": "Forest classification (Complete)",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice. Name the model forested_custom_fit and display a tidy output of the model.\n\nforested_custom_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ elevation + tree_no_tree + lat + lon + temp_annual_mean, data = forested_train)\ntidy(forested_custom_fit)\n\n# A tibble: 6 × 5\n  term                 estimate std.error statistic   p.value\n  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)         48.2       6.06         7.96  1.71e- 15\n2 elevation           -0.000311  0.000384    -0.811 4.17e-  1\n3 tree_no_treeNo tree  3.35      0.0925      36.3   4.02e-288\n4 lat                 -0.313     0.0642      -4.87  1.09e-  6\n5 lon                  0.311     0.0288      10.8   3.81e- 27\n6 temp_annual_mean     0.270     0.0819       3.30  9.78e-  4"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#predict",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#predict",
    "title": "Forest classification (Complete)",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_custom_aug &lt;- augment(forested_custom_fit, new_data = forested_test)\nforested_custom_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.877    0.123  Yes       2005       113      -25        96\n 2 Yes            0.829    0.171  Yes       2005       736      -27       -96\n 3 Yes            0.855    0.145  Yes       2005       224      -65       -75\n 4 Yes            0.957    0.0431 Yes       2003      1031      -49        86\n 5 Yes            0.728    0.272  No        2005      1713      -66        75\n 6 Yes            0.982    0.0175 Yes       2014      1612       30       -95\n 7 No             0.0765   0.924  No        2014       507       44       -89\n 8 Yes            0.889    0.111  Yes       2014       940      -93        35\n 9 Yes            0.659    0.341  No        2014       246       22       -97\n10 No             0.0877   0.912  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#evaluate",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#evaluate",
    "title": "Forest classification (Complete)",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_custom_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        864  0.9  True positive \n2 No          Yes         98  0.1  False negative\n3 Yes         No         124  0.15 False positive\n4 No          No         691  0.85 True negative \n\n\nAnother commonly used display of this information is a confusion matrix. Create this using the conf_mat() function. You will need to review the documentation for the function to determine how to use it.\n\nconf_mat(\n  forested_custom_aug, \n  truth = forested, \n  estimate = .pred_class\n)\n\n          Truth\nPrediction Yes  No\n       Yes 864 124\n       No   98 691"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#sensitivity-specificity-roc-curve",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#sensitivity-specificity-roc-curve",
    "title": "Forest classification (Complete)",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_custom_roc &lt;- roc_curve(forested_custom_aug, truth = forested, .pred_Yes)\nforested_custom_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1  -Inf          0                 1\n 2     0.0186     0                 1\n 3     0.0202     0.00123           1\n 4     0.0204     0.00245           1\n 5     0.0207     0.00368           1\n 6     0.0227     0.00491           1\n 7     0.0286     0.00613           1\n 8     0.0298     0.00736           1\n 9     0.0299     0.00859           1\n10     0.0300     0.00982           1\n# ℹ 1,769 more rows\n\nggplot(forested_custom_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#fit-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#fit-1",
    "title": "Forest classification (Complete)",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on all predictors available. Name the model forested_full_fit and display a tidy output of the model.\n\nforested_full_fit &lt;- logistic_reg() |&gt;\n  fit(forested ~ ., data = forested_train)\ntidy(forested_full_fit)\n\n# A tibble: 20 × 5\n   term                             estimate std.error statistic  p.value\n   &lt;chr&gt;                               &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n 1 (Intercept)                  -12.1        32.6       -0.371   7.11e- 1\n 2 year                           0.00456     0.0152     0.299   7.65e- 1\n 3 elevation                     -0.00277     0.000639  -4.33    1.47e- 5\n 4 eastness                      -0.000910    0.000734  -1.24    2.15e- 1\n 5 northness                      0.00208     0.000745   2.79    5.26e- 3\n 6 roughness                     -0.00399     0.00146   -2.73    6.29e- 3\n 7 tree_no_treeNo tree            1.25        0.136      9.23    2.61e-20\n 8 dew_temp                      -0.125       0.176     -0.712   4.76e- 1\n 9 precip_annual                 -0.0000895   0.000100  -0.895   3.71e- 1\n10 temp_annual_mean              -7.30       12.4       -0.587   5.57e- 1\n11 temp_annual_min                0.819       0.103      7.93    2.20e-15\n12 temp_annual_max                2.59        6.22       0.417   6.77e- 1\n13 temp_january_min               3.34        6.21       0.538   5.91e- 1\n14 vapor_min                      0.00000990  0.00353    0.00280 9.98e- 1\n15 vapor_max                      0.00925     0.00132    7.00    2.62e-12\n16 canopy_cover                  -0.0446      0.00366  -12.2     4.18e-34\n17 lon                           -0.0953      0.0559    -1.71    8.80e- 2\n18 lat                            0.0748      0.109      0.683   4.94e- 1\n19 land_typeNon-tree vegetation  -0.735       0.282     -2.61    9.05e- 3\n20 land_typeTree                 -1.58        0.297     -5.33    9.93e- 8"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#predict-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#predict-1",
    "title": "Forest classification (Complete)",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\nforested_full_aug &lt;- augment(forested_full_fit, new_data = forested_test)\nforested_full_aug\n\n# A tibble: 1,777 × 22\n   .pred_class .pred_Yes .pred_No forested  year elevation eastness northness\n   &lt;fct&gt;           &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes            0.930    0.0700 Yes       2005       113      -25        96\n 2 Yes            0.918    0.0822 Yes       2005       736      -27       -96\n 3 No             0.428    0.572  Yes       2005       224      -65       -75\n 4 Yes            0.972    0.0280 Yes       2003      1031      -49        86\n 5 Yes            0.633    0.367  No        2005      1713      -66        75\n 6 Yes            0.980    0.0201 Yes       2014      1612       30       -95\n 7 No             0.0436   0.956  No        2014       507       44       -89\n 8 Yes            0.845    0.155  Yes       2014       940      -93        35\n 9 No             0.0141   0.986  No        2014       246       22       -97\n10 No             0.0386   0.961  No        2014       419       86       -49\n# ℹ 1,767 more rows\n# ℹ 14 more variables: roughness &lt;dbl&gt;, tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;, temp_annual_min &lt;dbl&gt;,\n#   temp_annual_max &lt;dbl&gt;, temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;, lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#evaluate-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#evaluate-1",
    "title": "Forest classification (Complete)",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\nforested_full_aug |&gt;\n  count(.pred_class, forested) |&gt;\n  arrange(forested) |&gt;\n  group_by(forested) |&gt;\n  mutate(\n    p = round(n / sum(n), 2),\n    decision = case_when(\n      .pred_class == \"Yes\" & forested == \"Yes\" ~ \"True positive\",\n      .pred_class == \"Yes\" & forested == \"No\" ~ \"False positive\",\n      .pred_class == \"No\" & forested == \"Yes\" ~ \"False negative\",\n      .pred_class == \"No\" & forested == \"No\" ~ \"True negative\"\n    )\n  )\n\n# A tibble: 4 × 5\n# Groups:   forested [2]\n  .pred_class forested     n     p decision      \n  &lt;fct&gt;       &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt; &lt;chr&gt;         \n1 Yes         Yes        876  0.91 True positive \n2 No          Yes         86  0.09 False negative\n3 Yes         No          85  0.1  False positive\n4 No          No         730  0.9  True negative"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#sensitivity-specificity-roc-curve-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification-complete.html#sensitivity-specificity-roc-curve-1",
    "title": "Forest classification (Complete)",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\nforested_full_roc &lt;- roc_curve(forested_full_aug, truth = forested, .pred_Yes)\nforested_full_roc\n\n# A tibble: 1,779 × 3\n   .threshold specificity sensitivity\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 -Inf           0                 1\n 2    0.00106     0                 1\n 3    0.00107     0.00123           1\n 4    0.00217     0.00245           1\n 5    0.00287     0.00368           1\n 6    0.00290     0.00491           1\n 7    0.00290     0.00613           1\n 8    0.00309     0.00736           1\n 9    0.00321     0.00859           1\n10    0.00323     0.00982           1\n# ℹ 1,769 more rows\n\nggplot(forested_full_roc, aes(x = 1 - specificity, y = sensitivity)) +\n  geom_path() +\n  geom_abline(lty = 3) +\n  coord_equal()"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html",
    "title": "Building a spam filter (Complete)",
    "section": "",
    "text": "In this code along, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, …\nThe variables we’ll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#fit",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#fit",
    "title": "Building a spam filter (Complete)",
    "section": "Fit",
    "text": "Fit\nFit a linear regression model to whether an email is spam from the number of exclamation points in the email.\n\nlinear_reg() |&gt;\n  fit(as.numeric(spam) ~ exclaim_mess, data = email)\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = as.numeric(spam) ~ exclaim_mess, data = data)\n\nCoefficients:\n (Intercept)  exclaim_mess  \n   1.093e+00     2.604e-05"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#visualize",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#visualize",
    "title": "Building a spam filter (Complete)",
    "section": "Visualize",
    "text": "Visualize\nVisualizate the linear model.\n\nggplot(email, aes(x = exclaim_mess, y = as.numeric(spam), color = spam)) + \n  geom_jitter(alpha = 0.5) + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"black\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nIs the linear model a good fit for the data? Why or why not?\n\nNo."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#fit-1",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#fit-1",
    "title": "Building a spam filter (Complete)",
    "section": "Fit",
    "text": "Fit\nFit a logistic regression model to predict the probability an email is spam from the number of exclamation points in the email.\n\nlog_fit &lt;- logistic_reg() |&gt;\n  fit(spam ~ exclaim_mess, data = email)\n\ntidy(log_fit)\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)  -2.27      0.0553     -41.1     0    \n2 exclaim_mess  0.000272  0.000949     0.287   0.774"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#summarize",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#summarize",
    "title": "Building a spam filter (Complete)",
    "section": "Summarize",
    "text": "Summarize\nWrite the estimated model.\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#think",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#think",
    "title": "Building a spam filter (Complete)",
    "section": "Think",
    "text": "Think\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check). What are some trade offs you would consider as you set the decision-making threshold?\nAnswers will vary."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#do",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter-complete.html#do",
    "title": "Building a spam filter (Complete)",
    "section": "Do",
    "text": "Do\nClassify the emails in this dataset as spam or not spam.\n\nlog_aug &lt;- augment(log_fit, email)\n\nggplot(log_aug, aes(x = exclaim_mess, y = spam, color = .pred_class)) +\n  geom_jitter(alpha = 0.5)"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html",
    "title": "Modeling fish (Complete)",
    "section": "",
    "text": "Practice modeling using the fish dataset on two common fish species in fish market sales.\n\nWe will use the tidyverse package for data wrangling and visualization and the tidymodels package for modeling.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\nThese data come from Kaggle and is commonly used in machine learning examples.\n\nfish &lt;- read_csv(\"https://data-science-with-r.github.io/data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nLet’s take a look at the data.\n\nfish\n\n# A tibble: 55 × 7\n   species weight length_vertical length_diagonal length_cross height width\n   &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bream      242            23.2            25.4         30     11.5  4.02\n 2 Bream      290            24              26.3         31.2   12.5  4.31\n 3 Bream      340            23.9            26.5         31.1   12.4  4.70\n 4 Bream      363            26.3            29           33.5   12.7  4.46\n 5 Bream      430            26.5            29           34     12.4  5.13\n 6 Bream      450            26.8            29.7         34.7   13.6  4.93\n 7 Bream      500            26.8            29.7         34.5   14.2  5.28\n 8 Bream      390            27.6            30           35     12.7  4.69\n 9 Bream      450            27.6            30           35.1   14.0  4.84\n10 Bream      500            28.5            30.7         36.2   14.2  4.96\n# ℹ 45 more rows"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#goal",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#goal",
    "title": "Modeling fish (Complete)",
    "section": "",
    "text": "Practice modeling using the fish dataset on two common fish species in fish market sales."
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#packages",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#packages",
    "title": "Modeling fish (Complete)",
    "section": "",
    "text": "We will use the tidyverse package for data wrangling and visualization and the tidymodels package for modeling.\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#data",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#data",
    "title": "Modeling fish (Complete)",
    "section": "",
    "text": "These data come from Kaggle and is commonly used in machine learning examples.\n\nfish &lt;- read_csv(\"https://data-science-with-r.github.io/data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nLet’s take a look at the data.\n\nfish\n\n# A tibble: 55 × 7\n   species weight length_vertical length_diagonal length_cross height width\n   &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bream      242            23.2            25.4         30     11.5  4.02\n 2 Bream      290            24              26.3         31.2   12.5  4.31\n 3 Bream      340            23.9            26.5         31.1   12.4  4.70\n 4 Bream      363            26.3            29           33.5   12.7  4.46\n 5 Bream      430            26.5            29           34     12.4  5.13\n 6 Bream      450            26.8            29.7         34.7   13.6  4.93\n 7 Bream      500            26.8            29.7         34.5   14.2  5.28\n 8 Bream      390            27.6            30           35     12.7  4.69\n 9 Bream      450            27.6            30           35.1   14.0  4.84\n10 Bream      500            28.5            30.7         36.2   14.2  4.96\n# ℹ 45 more rows"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#visualizing-the-model",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#visualizing-the-model",
    "title": "Modeling fish (Complete)",
    "section": "Visualizing the model",
    "text": "Visualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish, predicting weight from height.\n\nCreate an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n\n\n\n\n\n\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\n\nStart from the bottom and go up. Identify the first and last point and draw a line through most the others.\n\nNow, let R draw the line for you! Hint: Use geom_smooth().\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. lengths of fish\",\n    x = \"Head-to-tail lentgh (cm)\",\n    y = \"Weight of fish (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWhat types of questions can this plot help answer?\n\nIs there a relationship between fish heights and weights of fish?\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAt 10 cm, we estimate a weight of 375 grams. At 15 cm, we estimate a weight of 600 grams At 20 cm, we estimate a weight of 975 grams. 20 cm would be considered extrapolation.\n\nWhat is a residual?\n\nDifference between predicted and observed."
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#model-fitting",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#model-fitting",
    "title": "Modeling fish (Complete)",
    "section": "Model fitting",
    "text": "Model fitting\n\nFit a model to predict fish weights from their heights.\n\n\nfish_hw_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ height, data = fish)\n\nfish_hw_fit\n\nparsnip model object\n\n\nCall:\nstats::lm(formula = weight ~ height, data = data)\n\nCoefficients:\n(Intercept)       height  \n    -288.42        60.92  \n\n\n\nPredict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\nx &lt;- c(10, 15, 20)\n-288 + 60.92 * x\n\n[1] 321.2 625.8 930.4\n\n\n\nCalculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\nfish_hw_aug &lt;- augment(fish_hw_fit, new_data = fish)\n\nggplot(fish_hw_aug, aes(x = height, y = weight)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +  \n  geom_segment(aes(xend = height, yend = .pred), color = \"gray\") +  \n  geom_point(aes(y = .pred), shape = \"circle open\") + \n  theme_minimal() +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    subtitle = \"Residuals\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#model-summary",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#model-summary",
    "title": "Modeling fish (Complete)",
    "section": "Model summary",
    "text": "Model summary\n\nDisplay the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\nfish_hw_tidy &lt;- tidy(fish_hw_fit)\nfish_hw_tidy\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   -288.      34.0      -8.49 1.83e-11\n2 height          60.9      2.64     23.1  2.40e-29\n\n\n\nWrite out your model using mathematical notation.\n\n\\(\\widehat{weight} = -288 + 60.9 \\times height\\)"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#correlation",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#correlation",
    "title": "Modeling fish (Complete)",
    "section": "Correlation",
    "text": "Correlation\nWe can also assess correlation between two quantitative variables.\n\nWhat is correlation? What are values correlation can take?\n\nStrength and direction of a linear relationship. It’s bounded by -1 and 1.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\nWhat is the correlation between heights and weights of fish?\n\n\nfish |&gt;\n  summarize(r = cor(height, weight))\n\n# A tibble: 1 × 1\n      r\n  &lt;dbl&gt;\n1 0.954"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#adding-a-third-variable",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#adding-a-third-variable",
    "title": "Modeling fish (Complete)",
    "section": "Adding a third variable",
    "text": "Adding a third variable\n\nDoes the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\nggplot(fish, aes(x = height, y = weight, color = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#fitting-other-models",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish-complete.html#fitting-other-models",
    "title": "Modeling fish (Complete)",
    "section": "Fitting other models",
    "text": "Fitting other models\n\nWe can fit more models than just a straight line. Use method = \"loess\". What is different from the plot created before?\n\n\nggplot(fish, aes(x = height, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"loess\") +\n  labs(\n    title = \"Weights vs. heights of fish\",\n    x = \"Height (cm)\",\n    y = \"Weight (gr)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#packages",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#packages",
    "title": "Main and interaction effects",
    "section": "Packages",
    "text": "Packages\n\n\nDAAG for data\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(DAAG)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#data-book-weight-and-volume",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#data-book-weight-and-volume",
    "title": "Main and interaction effects",
    "section": "Data: Book weight and volume",
    "text": "Data: Book weight and volume\nThe allbacks data frame gives measurements on the volume and weights of 15 books, some of which are paperback and some of which are hardback\n\n\n\nvolume - cubic centimetres\narea - square centimetres\nweight - grams\ncover - hb or pb\n\n\n\n\n# A tibble: 15 × 4\n   volume  area weight cover\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;\n 1    885   382    800 hb   \n 2   1016   468    950 hb   \n 3   1125   387   1050 hb   \n 4    239   371    350 hb   \n 5    701   371    750 hb   \n 6    641   367    600 hb   \n 7   1228   396   1075 hb   \n 8    412     0    250 pb   \n 9    953     0    700 pb   \n10    929     0    650 pb   \n11   1492     0    975 pb   \n12    419     0    350 pb   \n13   1010     0    950 pb   \n14    595     0    425 pb   \n15   1034     0    725 pb   \n\n\n\n\n\nThese books are from the bookshelf of J. H. Maindonald at Australian National University."
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#two-possible-explanations",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#two-possible-explanations",
    "title": "Main and interaction effects",
    "section": "Two possible explanations",
    "text": "Two possible explanations\n\n\n\nSuppose we want to predict weights of books from their volume and cover type (hardback vs. paperback). Do these visualizations suggest that a model that doesn’t allow for the rate of change in weight to vary by cover type (parallel lines) is a better fit or a model that does allow (non-parallel lines)?"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#in-pursuit-of-occams-razor",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#in-pursuit-of-occams-razor",
    "title": "Main and interaction effects",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\nOccam’s Razor states that among competing hypotheses that predict equally well, the one with the fewest assumptions should be selected.\nModel selection follows this principle.\nWe only want to add another predictor to the model if the addition of that variable brings something valuable in terms of predictive power to the model.\nIn other words, we prefer the simplest best model, i.e. parsimonious model."
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#in-pursuit-of-occams-razor-1",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#in-pursuit-of-occams-razor-1",
    "title": "Main and interaction effects",
    "section": "In pursuit of Occam’s razor",
    "text": "In pursuit of Occam’s razor\n\n\n\nVisually, which of the two models is preferable under Occam’s razor?"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#model-1-volume-cover",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#model-1-volume-cover",
    "title": "Main and interaction effects",
    "section": "Model 1: volume + cover\n",
    "text": "Model 1: volume + cover\n\nMain effects: Rate of change for weight as volume increases is the same for hardback and paperback books.\n\nallbacks_main_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover, data = allbacks)\n\ntidy(allbacks_main_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672    \n\n\n\n\nglance(allbacks_main_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1     0.927         0.915  78.2      76.7 0.000000145     2\n# ℹ 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;,\n#   deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#model-2-volume-cover-volumecover",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#model-2-volume-cover-volumecover",
    "title": "Main and interaction effects",
    "section": "Model 2: volume + cover + volume*cover\n",
    "text": "Model 2: volume + cover + volume*cover\n\nInteraction effects: Rate of change for weight as volume increases is different for hardback and paperback books.\n\nallbacks_int_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover + volume*cover, data = allbacks)\n\ntidy(allbacks_int_fit)\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic    p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)     162.       86.5        1.87  0.0887    \n2 volume            0.762     0.0972     7.84  0.00000794\n3 coverpb        -120.      116.        -1.04  0.321     \n4 volume:coverpb   -0.0757    0.128     -0.592 0.566     \n\n\n\n\nglance(allbacks_main_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1     0.927         0.915  78.2      76.7 0.000000145     2\n# ℹ 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;,\n#   deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#rs-got-your-back",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#rs-got-your-back",
    "title": "Main and interaction effects",
    "section": "R’s got your back!",
    "text": "R’s got your back!\nWhen you add an interaction effect to a model, R will always add the main effects of those variables too, even if you leave them out of your model formula:\n\nlinear_reg() |&gt;\n  fit(weight ~ volume*cover, data = allbacks) |&gt;\n  tidy()\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic    p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)     162.       86.5        1.87  0.0887    \n2 volume            0.762     0.0972     7.84  0.00000794\n3 coverpb        -120.      116.        -1.04  0.321     \n4 volume:coverpb   -0.0757    0.128     -0.592 0.566"
  },
  {
    "objectID": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#choosing-between-models",
    "href": "slides/2-2-main-interaction-effects/2-2-main-interaction-effects.html#choosing-between-models",
    "title": "Main and interaction effects",
    "section": "Choosing between models",
    "text": "Choosing between models\nThe model with the interaction effects has more predictors, and remember that when comparing models with different numbers of predictors, we use adjusted \\(R^2\\) for model selection:\n\n\n\\(R^2\\):\n\nglance(allbacks_main_fit)$r.squared\n\n[1] 0.9274776\n\nglance(allbacks_int_fit)$r.squared\n\n[1] 0.9297137\n\n\n\nAdjusted \\(R^2\\):\n\nglance(allbacks_main_fit)$adj.r.squared\n\n[1] 0.9153905\n\nglance(allbacks_int_fit)$adj.r.squared\n\n[1] 0.9105447\n\n\n\n\n\n\\(R^2\\) is higher for the model with the interaction effect.\nAdjusted \\(R^2\\) is not higher for the model with the interaction effect, therefore we do not need the interaction effect, the main effects model is good enough!"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling",
    "title": "Language of models",
    "section": "Modeling",
    "text": "Modeling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but remember there are many many other types of models too!)"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-cars",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-cars",
    "title": "Language of models",
    "section": "Modeling cars",
    "text": "Modeling cars\n\n\nWhat is the relationship between cars’ weights and their mileage?\nWhat is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modelling-cars",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modelling-cars",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nDescribe: What is the relationship between cars’ weights and their mileage?"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modelling-cars-1",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modelling-cars-1",
    "title": "Language of models",
    "section": "Modelling cars",
    "text": "Modelling cars\n\nPredict: What is your best guess for a car’s MPG that weighs 3,500 pounds?"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-2",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-2",
    "title": "Language of models",
    "section": "Modeling",
    "text": "Modeling\n\nUse models to explain the relationship between variables and to make predictions\nFor now we will focus on linear models (but there are many many other types of models too!)"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-vocabulary",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#modeling-vocabulary",
    "title": "Language of models",
    "section": "Modeling vocabulary",
    "text": "Modeling vocabulary\n\nOutcome: Variable whose behavior or variation you are trying to understand, on the y-axis (aka response variable, dependent variable)\nPredictor(s): Other variable(s) that you want to use to explain the variation in the outcome, on the x-axis (aka explanatory variable(s), independent variable(s))\nModel function: The regression line for predicting the outcome variable from the predictor variable(s), comprised generally of an intercept and a slope for each predictor\nPredicted value: Output of the model function, which gives the typical (expected) value of the outcome conditioning on the predictor\n\nResiduals: A measure of how far each case’s observed value is from its predicted value (based on a particular model)\n\nResidual = Observed value - Predicted value\nTells how far above/below the expected value each case is"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#predictor",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#predictor",
    "title": "Language of models",
    "section": "Predictor",
    "text": "Predictor\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#outcome",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#outcome",
    "title": "Language of models",
    "section": "Outcome",
    "text": "Outcome\n\n\n\n\n\n\n\n\nmpg\nwt\n\n\n\n21\n2.62\n\n\n21\n2.875\n\n\n22.8\n2.32\n\n\n21.4\n3.215\n\n\n18.7\n3.44\n\n\n18.1\n3.46\n\n\n...\n..."
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line",
    "title": "Language of models",
    "section": "Regression line",
    "text": "Regression line"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line-slope",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line-slope",
    "title": "Language of models",
    "section": "Regression line: slope",
    "text": "Regression line: slope"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line-intercept",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#regression-line-intercept",
    "title": "Language of models",
    "section": "Regression line: intercept",
    "text": "Regression line: intercept"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#correlation",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#correlation",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#correlation-1",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#correlation-1",
    "title": "Language of models",
    "section": "Correlation",
    "text": "Correlation\n\nRanges between -1 and 1.\nSame sign as the slope."
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#visualizing-the-model",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#visualizing-the-model",
    "title": "Language of models",
    "section": "Visualizing the model",
    "text": "Visualizing the model\n\nggplot(mtcars, aes(x = wt, y = mpg)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#residuals",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#residuals",
    "title": "Language of models",
    "section": "Residuals",
    "text": "Residuals"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#extending-regression-lines",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#extending-regression-lines",
    "title": "Language of models",
    "section": "Extending regression lines",
    "text": "Extending regression lines"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#models---upsides-and-downsides",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#models---upsides-and-downsides",
    "title": "Language of models",
    "section": "Models - upsides and downsides",
    "text": "Models - upsides and downsides\n\nModels can sometimes reveal patterns that are not evident in a graph of the data. This is a great advantage of modeling over simple visual inspection of data.\nThere is a real risk, however, that a model is imposing structure that is not really there on the scatter of data, just as people imagine animal shapes in the stars. A skeptical approach is always warranted."
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#variation-around-the-model",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#variation-around-the-model",
    "title": "Language of models",
    "section": "Variation around the model…",
    "text": "Variation around the model…\nis just as important as the model, if not more!\nStatistics is the explanation of variation in the context of what remains unexplained.\n\nThe scatter suggests that there might be other factors that account for large parts of painting-to-painting variability, or perhaps just that randomness plays a big role.\nAdding more explanatory variables to a model can sometimes usefully reduce the size of the scatter around the model. (We’ll talk more about this later.)"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#how-do-we-use-models",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#how-do-we-use-models",
    "title": "Language of models",
    "section": "How do we use models?",
    "text": "How do we use models?\n\nPredict / classify: Plug in the value(s) of predictor(s) to the model to obtain the predicted value of the outcome\nDescribe: Quantify the relationship between predictor(s) and outcome with slopes"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#predict-classify-1",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#predict-classify-1",
    "title": "Language of models",
    "section": "Predict / classify",
    "text": "Predict / classify\n\nHow do self-driving cars decide whether an object in front of them is a human, another car, or a trash can?\nHow does an online shopping website decide which ad to serve to you for the next item you might purchase?\nWhat happens if either of these get it wrong?"
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#leisure-commute-physical-activity-and-bp",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\n\nRelation Between Leisure Time, Commuting, and Occupational Physical Activity With Blood Pressure in 125,402 Adults: The Lifelines Cohort\nByambasukh, Oyuntugs, Harold Snieder, and Eva Corpeleijn. “Relation between leisure time, commuting, and occupational physical activity with blood pressure in 125 402 adults: the lifelines cohort.” Journal of the American Heart Association 9.4 (2020): e014313."
  },
  {
    "objectID": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "href": "slides/1-1-2-language-of-models/1-1-2-language-of-models.html#leisure-commute-physical-activity-and-bp-1",
    "title": "Language of models",
    "section": "Leisure, commute, physical activity and BP",
    "text": "Leisure, commute, physical activity and BP\nBackground: Whether all domains of daily‐life moderate‐to‐vigorous physical activity (MVPA) are associated with lower blood pressure (BP) and how this association depends on age and body mass index remains unclear.\nMethods and Results: In the population‐based Lifelines cohort (N=125,402), MVPA was assessed by the Short Questionnaire to Assess Health‐Enhancing Physical Activity, a validated questionnaire in different domains such as commuting, leisure‐time, and occupational PA. BP was assessed using the last 3 of 10 measurements after 10 minutes’ rest in the supine position. Hypertension was defined as systolic BP ≥140 mm Hg and/or diastolic BP ≥90 mm Hg and/or use of antihypertensives. In regression analysis, higher commuting and leisure‐time but not occupational MVPA related to lower BP and lower hypertension risk. Commuting‐and‐leisure‐time MVPA was associated with BP in a dose‐dependent manner. β Coefficients (95% CI) from linear regression analyses were −1.64 (−2.03 to −1.24), −2.29 (−2.68 to −1.90), and finally −2.90 (−3.29 to −2.50) mm Hg systolic BP for the low, middle, and highest tertile of MVPA compared with “No MVPA” as the reference group after adjusting for age, sex, education, smoking and alcohol use. Further adjustment for body mass index attenuated the associations by 30% to 50%, but more MVPA remained significantly associated with lower BP and lower risk of hypertension. This association was age dependent. β Coefficients (95% CI) for the highest tertiles of commuting‐and‐leisure‐time MVPA were −1.67 (−2.20 to −1.15), −3.39 (−3.94 to −2.82) and −4.64 (−6.15 to −3.14) mm Hg systolic BP in adults &lt;40, 40 to 60, and &gt;60 years, respectively.\nConclusions: Higher commuting and leisure‐time but not occupational MVPA were significantly associated with lower BP and lower hypertension risk at all ages, but these associations were stronger in older adults."
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#packages",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#packages",
    "title": "Linear regression with multiple predictors",
    "section": "Packages",
    "text": "Packages\n\n\nDAAG for data\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(DAAG)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#data-book-weight-and-volume",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#data-book-weight-and-volume",
    "title": "Linear regression with multiple predictors",
    "section": "Data: Book weight and volume",
    "text": "Data: Book weight and volume\nThe allbacks data frame gives measurements on the volume and weight of 15 books, some of which are paperback and some of which are hardback\n\n\n- volume - cubic centimetres\n- area - square centimetres\n- weight - grams\n- cover - hb or pb\n\n\n\n# A tibble: 15 × 4\n   volume  area weight cover\n    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;\n 1    885   382    800 hb   \n 2   1016   468    950 hb   \n 3   1125   387   1050 hb   \n 4    239   371    350 hb   \n 5    701   371    750 hb   \n 6    641   367    600 hb   \n 7   1228   396   1075 hb   \n 8    412     0    250 pb   \n 9    953     0    700 pb   \n10    929     0    650 pb   \n11   1492     0    975 pb   \n12    419     0    350 pb   \n13   1010     0    950 pb   \n14    595     0    425 pb   \n15   1034     0    725 pb   \n\n\n\n\n\nThese books are from the bookshelf of J. H. Maindonald at Australian National University."
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#book-weight-vs.-volume",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#book-weight-vs.-volume",
    "title": "Linear regression with multiple predictors",
    "section": "Book weight vs. volume",
    "text": "Book weight vs. volume\n\n\n\nallbacks_1_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume, data = allbacks)\n\ntidy(allbacks_1_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)  108.      88.4         1.22 0.245     \n2 volume         0.709    0.0975      7.27 0.00000626"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#book-weight-vs.-volume-and-cover",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#book-weight-vs.-volume-and-cover",
    "title": "Linear regression with multiple predictors",
    "section": "Book weight vs. volume and cover",
    "text": "Book weight vs. volume and cover\n\n\n\nallbacks_2_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover, data = allbacks)\n\ntidy(allbacks_2_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#interpretation-of-estimates",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#interpretation-of-estimates",
    "title": "Linear regression with multiple predictors",
    "section": "Interpretation of estimates",
    "text": "Interpretation of estimates\n\ntidy(allbacks_2_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672    \n\n\n\n\nSlope - volume: Keeping cover constant, for each additional cubic centimetre books are larger in volume, the model predicts the weight to be higher, on average, by 0.718 grams.\nSlope - cover: Keeping volume constant, the model predicts that paperback books weigh, on average, by 184 grams less than hardback books.\nIntercept: The model predicts that hardback books with 0 volume are expected to weigh 198 grams, on average. (Doesn’t make sense in context.)"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#r2",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#r2",
    "title": "Linear regression with multiple predictors",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\\(R^2\\) is the percentage of variability in the outcome explained by the regression model.\n\n\nModel 1: weight ~ volume\n\n\n\nglance(allbacks_1_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic    p.value    df\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;\n1     0.803         0.787  124.      52.9 0.00000626     1\n# ℹ 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;,\n#   deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\nModel 2: weight ~ volume + cover\n\n\n\nglance(allbacks_2_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n1     0.927         0.915  78.2      76.7 0.000000145     2\n# ℹ 6 more variables: logLik &lt;dbl&gt;, AIC &lt;dbl&gt;, BIC &lt;dbl&gt;,\n#   deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\n\n\n\\(R^2\\) increases when any predictor is added to the model."
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#adjusted-r2",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#adjusted-r2",
    "title": "Linear regression with multiple predictors",
    "section": "Adjusted \\(R^2\\)\n",
    "text": "Adjusted \\(R^2\\)\n\nAdjusted \\(R^2\\) adds a penalty to \\(R^2\\) for additional predictors in the model, and is therefore a (more) objective measure for comparing models with different numbers of predictors.\n\n\nModel 1: weight ~ volume\n\n\n\nglance(allbacks_1_fit)$adj.r.squared\n\n[1] 0.7874526\n\n\n\n\n\nModel 2: weight ~ volume + cover\n\n\n\nglance(allbacks_2_fit)$adj.r.squared\n\n[1] 0.9153905\n\n\n\n\n\nAdjusted \\(R^2\\) is higher for the model with volume and cover as predictors, and it is therefore the preferable model for predicting weight."
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#model-1---visualized",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#model-1---visualized",
    "title": "Linear regression with multiple predictors",
    "section": "Model 1 - visualized",
    "text": "Model 1 - visualized\n\nglance(allbacks_1_fit) |&gt;\n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.803         0.787"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#model-2---visualized",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#model-2---visualized",
    "title": "Linear regression with multiple predictors",
    "section": "Model 2 - visualized",
    "text": "Model 2 - visualized\n\nglance(allbacks_2_fit) |&gt;\n  select(r.squared, adj.r.squared)\n\n# A tibble: 1 × 2\n  r.squared adj.r.squared\n      &lt;dbl&gt;         &lt;dbl&gt;\n1     0.927         0.915"
  },
  {
    "objectID": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#takeaways",
    "href": "slides/2-1-linear-regression-multiple-predictors/2-1-linear-regression-multiple-predictors.html#takeaways",
    "title": "Linear regression with multiple predictors",
    "section": "Takeaways",
    "text": "Takeaways\n\nWhen interpreting slope coefficients for multiple regression models we need to state that one predictor is kept constant while the other increases.\nAdjusted R-squared is useful when comparing models with different numbers of predictors - it helps you balance model complexity with explanatory power."
  },
  {
    "objectID": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#packages",
    "href": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#packages",
    "title": "Clasification and decision errors",
    "section": "Packages",
    "text": "Packages\n\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#is-the-e-mail-spam-or-not",
    "href": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#is-the-e-mail-spam-or-not",
    "title": "Clasification and decision errors",
    "section": "Is the e-mail spam or not?",
    "text": "Is the e-mail spam or not?\n\n\n\\(\\mathbf{x}\\): Word and character counts, etc. in an e-mail\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's spam}\\\\\n0 & \\text{it's legit}\n\\end{cases}\n\\]\n\n\n\n\nSubject: Congratulations! You’ve Been Selected for an Exclusive Reward 🎁\nDear Customer,\nYou have been chosen as one of our preferred recipients to receive a special complimentary gift. This is our way of thanking you for your continued interest in our services.\nTo claim your reward, simply complete our short survey. Your participation takes only 60 seconds, and your prize will be shipped at no cost to you.\nClick here to start your survey and claim your reward [Claim Reward Link]\nThis exclusive offer is available for the next 48 hours only. Don’t miss your chance to enjoy this limited opportunity.\nWarm regards,\nPromotions Team\nExclusive Rewards Center\n\n\n\n\n\n\nSample spam email language generated by Chat GPT with the prompt “Generate a fake “promotional” style spam email that doesn’t contain any explicit words.”"
  },
  {
    "objectID": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#prediction-clssification",
    "href": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#prediction-clssification",
    "title": "Clasification and decision errors",
    "section": "Prediction / clssification",
    "text": "Prediction / clssification\n\n\n\n\n\n\n\n\n\nEmail is spam\nEmail is not spam\n\n\n\n\nEmail labelled spam\nTrue positive\nFalse positive (Type 1 error)\n\n\nEmail labelled not spam\nFalse negative (Type 2 error)\nTrue negative\n\n\n\n\nFalse negative rate = P(Labelled not spam | Email spam) = FN / (TP + FN)\nFalse positive rate = P(Labelled spam | Email not spam) = FP / (FP + TN)"
  },
  {
    "objectID": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-in-regression",
    "href": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-in-regression",
    "title": "Outliers in linear regression",
    "section": "Outliers in regression",
    "text": "Outliers in regression\n\nOutliers are observations that fall far from the main cloud of points.\n\nThey can be outlying in:\n\nthe \\(x\\) direction,\nthe \\(y\\) direction, or\nboth.\n\n\nHowever, being outlying in a univariate sense does not always mean being outlying from the bivariate model.\nPoints that are in-line with the bivariate model usually do not influence the least squares line, even if they are extreme in \\(x\\), \\(y\\), or both."
  },
  {
    "objectID": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-and-influence",
    "href": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-and-influence",
    "title": "Outliers in linear regression",
    "section": "Outliers and influence",
    "text": "Outliers and influence\n\n\n\n\n\n\n\n\n\n\n\n\n\nA: One outlier in the \\(y\\) direction, also outlying in the bivariate model; slightly influences the regression line.\n\nB: One outlier on the right (outlying in \\(x\\) and \\(y\\), but not outlying in the bivariate model); close to the regression line and not influential.\n\nC: One point far from the cloud (outlying in \\(x\\), \\(y\\), and bivariate model); pulls the regression line upward, worsening fit for the main data."
  },
  {
    "objectID": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-and-influence-1",
    "href": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#outliers-and-influence-1",
    "title": "Outliers in linear regression",
    "section": "Outliers and influence",
    "text": "Outliers and influence\n\n\n\n\n\n\n\n\n\n\n\n\n\nD: A secondary small cloud of four points (outlying in \\(x\\) and bivariate model); strongly influences the regression line, creating poor fit.\n\nE: Outlier far right (outlying in \\(x\\) and \\(y\\)); the regression line is largely controlled by this single point, imposing a trend where there is none.\n\nF: One outlier far away (outlying in \\(x\\) and \\(y\\)), but in-line with the model; has little influence."
  },
  {
    "objectID": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#types-of-outliers",
    "href": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#types-of-outliers",
    "title": "Outliers in linear regression",
    "section": "Types of outliers",
    "text": "Types of outliers\n\nOutliers: Points or groups of points that stand out from the rest of the data.\nLeverage points: Points that fall horizontally away from the center of the cloud tend to pull harder on the line, so we call them points with high leverage or leverage points.\n\nInfluential points: Outliers, generally high leverage points, that actually alter the slope or position of the regression line.\n\nWe say a point is influential if omitting it would substantially change the regression model."
  },
  {
    "objectID": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#practical-advice",
    "href": "slides/1-3-outliers-linear-regression/1-3-outliers-linear-regression.html#practical-advice",
    "title": "Outliers in linear regression",
    "section": "Practical advice",
    "text": "Practical advice\n\nTest your analysis with and without outliers.\nCompare and discuss the impact of outliers on model fit.\nPresent both models to stakeholders to choose the most reasonable interpretation.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nRemoving outliers should only be done with strong justification – excluding interesting or extreme cases can lead to misleading models, poor predictive performance, and flawed conclusions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n Modeling and inference",
    "section": "",
    "text": "Title\n\n\n\n\n\n\nWelcome\n\n\n\n\n\nLanguage of models\n\n\n\n\n\nLinear regression with a numerical predictor\n\n\n\n\n\nLinear regression with a categorical predictor\n\n\n\n\n\nOutliers in linear regression\n\n\n\n\n\nLinear regression with multiple predictors\n\n\n\n\n\nMain and interaction effects\n\n\n\n\n\nLogistic regression\n\n\n\n\n\nClasification and decision errors\n\n\n\n\n\nOverfitting and spending your data\n\n\n\n\n\nQuantifying uncertainty\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#slides",
    "href": "index.html#slides",
    "title": "\n Modeling and inference",
    "section": "",
    "text": "Title\n\n\n\n\n\n\nWelcome\n\n\n\n\n\nLanguage of models\n\n\n\n\n\nLinear regression with a numerical predictor\n\n\n\n\n\nLinear regression with a categorical predictor\n\n\n\n\n\nOutliers in linear regression\n\n\n\n\n\nLinear regression with multiple predictors\n\n\n\n\n\nMain and interaction effects\n\n\n\n\n\nLogistic regression\n\n\n\n\n\nClasification and decision errors\n\n\n\n\n\nOverfitting and spending your data\n\n\n\n\n\nQuantifying uncertainty\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#code-alongs",
    "href": "index.html#code-alongs",
    "title": "\n Modeling and inference",
    "section": "Code alongs",
    "text": "Code alongs\n\n\n\n\nTitle\n\n\n\n\n\n\nModeling fish (Complete)\n\n\n\n\n\nModeling fish\n\n\n\n\n\nModeling loan interest rates (Complete)\n\n\n\n\n\nModeling loan interest rates\n\n\n\n\n\nBuilding a spam filter (Complete)\n\n\n\n\n\nBuilding a spam filter\n\n\n\n\n\nForest classification (Complete)\n\n\n\n\n\nForest classification\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#exercises",
    "href": "index.html#exercises",
    "title": "\n Modeling and inference",
    "section": "Exercises",
    "text": "Exercises\n\n\n\nTitle\n\n\n\nNo matching items"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#packages",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#packages",
    "title": "Logistic regression",
    "section": "Packages",
    "text": "Packages\n\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(ggthemes)\nlibrary(openintro)\nlibrary(fivethirtyeight)\nlibrary(palmerpenguins)"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-simple-linear-regression",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-simple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: Simple linear regression",
    "text": "Recap: Simple linear regression\nNumerical outcome and one numerical predictor:"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-multiple-linear-regression",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-multiple-linear-regression",
    "title": "Logistic regression",
    "section": "Recap: Multiple linear regression",
    "text": "Recap: Multiple linear regression\nNumerical outcome and one categorical predictor (two levels):"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-multiple-linear-regression-1",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#recap-multiple-linear-regression-1",
    "title": "Logistic regression",
    "section": "Recap: multiple linear regression",
    "text": "Recap: multiple linear regression\nNumerical outcome, numerical and categorical predictors:"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#a-binary-response",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#a-binary-response",
    "title": "Logistic regression",
    "section": "A binary response",
    "text": "A binary response\n\\[\ny =\n\\begin{cases}\n1 & &&\\text{eg. Yes, Win, True, Heads, Success}\\\\\n0 & &&\\text{eg. No, Lose, False, Tails, Failure}.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#who-cares",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#who-cares",
    "title": "Logistic regression",
    "section": "Who cares?",
    "text": "Who cares?\nIf we can model the relationship between predictors (\\(x\\)) and a binary outcome (\\(y\\)), we can use the model to do a special kind of prediction called classification."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-is-the-e-mail-spam-or-not",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-is-the-e-mail-spam-or-not",
    "title": "Logistic regression",
    "section": "Example: Is the e-mail spam or not?",
    "text": "Example: Is the e-mail spam or not?\n\n\n\\(\\mathbf{x}\\): Word and character counts in an e-mail\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's spam}\\\\\n0 & \\text{it's legit}\n\\end{cases}\n\\]\n\n\n\n\nSubject: Congratulations! You’ve Been Selected for an Exclusive Reward 🎁\nDear Customer,\nYou have been chosen as one of our preferred recipients to receive a special complimentary gift. This is our way of thanking you for your continued interest in our services.\nTo claim your reward, simply complete our short survey. Your participation takes only 60 seconds, and your prize will be shipped at no cost to you.\nClick here to start your survey and claim your reward [Claim Reward Link]\nThis exclusive offer is available for the next 48 hours only. Don’t miss your chance to enjoy this limited opportunity.\nWarm regards,\nPromotions Team\nExclusive Rewards Center\n\n\n\n\n\n\nSample spam email language generated by Chat GPT with the prompt “Generate a fake “promotional” style spam email that doesn’t contain any explicit words.”"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-is-it-cancer-or-not",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-is-it-cancer-or-not",
    "title": "Logistic regression",
    "section": "Example: Is it cancer or not?",
    "text": "Example: Is it cancer or not?\n\n\n\\(\\mathbf{x}\\): features in a medical image\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{it's cancer}\\\\\n0 & \\text{it's healthy}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nPhoto by National Cancer Institute on Unsplash."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-will-they-default",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-will-they-default",
    "title": "Logistic regression",
    "section": "Example: Will they default?",
    "text": "Example: Will they default?\n\n\n\\(\\mathbf{x}\\): financial and demographic info about a loan applicant\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{applicant is at risk of defaulting on loan}\\\\\n0 & \\text{applicant is safe}\n\\end{cases}\n\\]\n\n\n\n\n\n\n\nPhoto by PabitraKaity on Pixabay."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-will-they-reoffend",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#example-will-they-reoffend",
    "title": "Logistic regression",
    "section": "Example: Will they reoffend?",
    "text": "Example: Will they reoffend?\n\n\n\\(\\mathbf{x}\\): info about a criminal suspect and their case\n\n\\[\ny\n=\n\\begin{cases}\n1 & \\text{suspect is at risk of re-offending pre-trial}\\\\\n0 & \\text{suspect is safe}\n\\end{cases}\n\\]\n\n\n\n\nMachine Bias on ProPublica."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#how-do-we-model-this-type-of-data",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#how-do-we-model-this-type-of-data",
    "title": "Logistic regression",
    "section": "How do we model this type of data?",
    "text": "How do we model this type of data?"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#straight-line-of-best-fit-is-a-little-silly",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#straight-line-of-best-fit-is-a-little-silly",
    "title": "Logistic regression",
    "section": "Straight line of best fit is a little silly",
    "text": "Straight line of best fit is a little silly"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#instead-s-curve-of-best-fit",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#instead-s-curve-of-best-fit",
    "title": "Logistic regression",
    "section": "Instead: S-curve of best fit",
    "text": "Instead: S-curve of best fit\nInstead of modeling \\(y\\) directly, we model the probability that \\(y=1\\):\n\n\n\n\n\n\n\n\n\n“Given new email, what’s the probability that it’s spam?”\n“Given new image, what’s the probability that it’s cancer?”\n“Given new loan application, what’s the probability that applicant defaults?”"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#why-dont-we-model-y-directly",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#why-dont-we-model-y-directly",
    "title": "Logistic regression",
    "section": "Why don’t we model y directly?",
    "text": "Why don’t we model y directly?\n\n\nRecall regression with a numerical outcome:\n\nOur models do not output guarantees for \\(y\\), they output predictions that describe behavior on average;\n\n\n\n\n\n\nSimilar when modeling a binary outcome:\n\nOur models cannot directly guarantee that \\(y\\) will be zero or one. The correct analog to “on average” for a 0/1 outcome is “what’s the probability?”"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#so-what-is-this-s-curve-anyway",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#so-what-is-this-s-curve-anyway",
    "title": "Logistic regression",
    "section": "So, what is this S-curve, anyway?",
    "text": "So, what is this S-curve, anyway?\nIt’s the logistic function:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x}}{1+e^{\\beta_0+\\beta_1x}}.\n\\]\n\nIf you set p = Prob(y = 1) and do some algebra, you get the simple linear model for the log-odds:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x.\n\\]\nThis is called the logistic regression model."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#log-odds",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#log-odds",
    "title": "Logistic regression",
    "section": "Log-odds?",
    "text": "Log-odds?\n\n\\(p = Prob(y = 1)\\) is a probability – A number between 0 and 1\n\\(p / (1 - p)\\) is the odds – A number between 0 and \\(\\infty\\)\nThe log odds \\(log(p / (1 - p))\\) is a number between \\(-\\infty\\) and \\(\\infty\\), which is suitable for the linear model"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#logistic-regression",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#logistic-regression",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x\n\\]\n\nThe logit function \\(log(p / (1-p))\\) is an example of a link function that transforms the linear model to have an appropriate range\nThis is an example of a generalized linear model"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#estimation",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#estimation",
    "title": "Logistic regression",
    "section": "Estimation",
    "text": "Estimation\n\nWe estimate the parameters \\(\\beta_0\\), \\(\\beta_1\\), etc. using maximum likelihood (don’t worry about it) to get the “best fitting” S-curve\nThe fitted model is\n\n\\[\n\\log\\left(\\frac{\\widehat{p}}{1-\\widehat{p}}\\right)\n=\nb_0+b_1x\n\\]"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-1-pick-a-threshold",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-1-pick-a-threshold",
    "title": "Logistic regression",
    "section": "Step 1: Pick a threshold",
    "text": "Step 1: Pick a threshold\nSelect a number \\(0 &lt; p^* &lt; 1\\):\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\)\n\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-2-find-the-decision-boundary",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-2-find-the-decision-boundary",
    "title": "Logistic regression",
    "section": "Step 2: Find the decision boundary",
    "text": "Step 2: Find the decision boundary\nSolve for the x-value that matches the threshold:\n\n\n\n\n\n\n\n\n\nif \\(\\text{Prob}(y=1)\\leq p^*\\), then predict \\(\\widehat{y}=0\\)\n\nif \\(\\text{Prob}(y=1)&gt; p^*\\), then predict \\(\\widehat{y}=1\\)"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-3-classify-a-new-arrival",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#step-3-classify-a-new-arrival",
    "title": "Logistic regression",
    "section": "Step 3: Classify a new arrival",
    "text": "Step 3: Classify a new arrival\nA new data point is observed up with \\(x_{\\text{new}}\\). Which side of the boundary is it on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new observation\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new observation"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#lets-change-the-threshold",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#lets-change-the-threshold",
    "title": "Logistic regression",
    "section": "Let’s change the threshold",
    "text": "Let’s change the threshold\nA new data point is observed with \\(x_{\\text{new}}\\). Which side of the boundary are they on?\n\n\n\n\n\n\n\n\n\nif \\(x_{\\text{new}} \\leq x^\\star\\), then \\(\\text{Prob}(y=1)\\leq p^*\\), so predict \\(\\widehat{y}=0\\) for the new observation\nif \\(x_{\\text{new}} &gt; x^\\star\\), then \\(\\text{Prob}(y=1)&gt; p^*\\), so predict \\(\\widehat{y}=1\\) for the new observation"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#nothing-special-about-one-predictor",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#nothing-special-about-one-predictor",
    "title": "Logistic regression",
    "section": "Nothing special about one predictor…",
    "text": "Nothing special about one predictor…\nTwo numerical predictors and one binary outcome:"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#multiple-logistic-regression",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#multiple-logistic-regression",
    "title": "Logistic regression",
    "section": "“Multiple” logistic regression",
    "text": "“Multiple” logistic regression\nOn the probability scale:\n\\[\n\\text{Prob}(y = 1)\n=\n\\frac{e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}{1+e^{\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m}}.\n\\]\nFor the log-odds, a multiple linear regression:\n\\[\n\\log\\left(\\frac{p}{1-p}\\right)\n=\n\\beta_0+\\beta_1x_1+\\beta_2x_2+...+\\beta_mx_m.\n\\]"
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#decision-boundary-again",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#decision-boundary-again",
    "title": "Logistic regression",
    "section": "Decision boundary, again",
    "text": "Decision boundary, again\nIt’s linear! Consider two numerical predictors:\n\n\n\n\n\n\n\n\n\nif new \\((x_1,\\,x_2)\\) below, \\(\\text{Prob}(y=1)\\leq p^*\\). Predict \\(\\widehat{y}=0\\) for the new observation\nif new \\((x_1,\\,x_2)\\) above, \\(\\text{Prob}(y=1)&gt; p^*\\). Predict \\(\\widehat{y}=1\\) for the new observation"
  },
  {
    "objectID": "slides/1-1-1-welcome/1-1-1-welcome.html#transform---visualize",
    "href": "slides/1-1-1-welcome/1-1-1-welcome.html#transform---visualize",
    "title": "Welcome",
    "section": "Transform <-> visualize",
    "text": "Transform &lt;-&gt; visualize"
  },
  {
    "objectID": "slides/1-1-1-welcome/1-1-1-welcome.html#import---tidy",
    "href": "slides/1-1-1-welcome/1-1-1-welcome.html#import---tidy",
    "title": "Welcome",
    "section": "Import <-> tidy",
    "text": "Import &lt;-&gt; tidy"
  },
  {
    "objectID": "slides/1-1-1-welcome/1-1-1-welcome.html#data-science-ethics",
    "href": "slides/1-1-1-welcome/1-1-1-welcome.html#data-science-ethics",
    "title": "Welcome",
    "section": "Data science ethics",
    "text": "Data science ethics\n\nMisrepresentation\nData privacy\nAlgorithmic bias"
  },
  {
    "objectID": "slides/1-1-1-welcome/1-1-1-welcome.html#modeling-and-inference",
    "href": "slides/1-1-1-welcome/1-1-1-welcome.html#modeling-and-inference",
    "title": "Welcome",
    "section": "Modeling and inference",
    "text": "Modeling and inference\n\n\n\n\n\n\n\n\n\nFitting, interpreting, selecting, and evaluating models\nPrediction, classification, and assessing accuracy\nMaking inferences and quantifying uncertainty"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#packages",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#packages",
    "title": "Overfitting and spending your data",
    "section": "Packages",
    "text": "Packages\n\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\nforested for data\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data",
    "title": "Overfitting and spending your data",
    "section": "Data",
    "text": "Data\n\nThe U.S. Forest Service maintains machine learning models to predict whether a plot of land is “forested.”\nThis classification is important for research, legislation, land management, etc. purposes.\nPlots are typically remeasured every 10 years.\nThe forested dataset contains the most recent measurement per plot."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested",
    "title": "Overfitting and spending your data",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nforested\n\n# A tibble: 7,107 × 19\n   forested  year elevation eastness northness roughness\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes       2005       881       90        43        63\n 2 Yes       2005       113      -25        96        30\n 3 No        2005       164      -84        53        13\n 4 Yes       2005       299       93        34         6\n 5 Yes       2005       806       47       -88        35\n 6 Yes       2005       736      -27       -96        53\n 7 Yes       2005       636      -48        87         3\n 8 Yes       2005       224      -65       -75         9\n 9 Yes       2005        52      -62        78        42\n10 Yes       2005      2240      -67       -74        99\n# ℹ 7,097 more rows\n# ℹ 13 more variables: tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;,\n#   temp_annual_min &lt;dbl&gt;, temp_annual_max &lt;dbl&gt;,\n#   temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested-1",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested-1",
    "title": "Overfitting and spending your data",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 200…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75…\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, …\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, …\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.3…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, …\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, …\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331,…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 8…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, …\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tre…"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested-2",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#data-forested-2",
    "title": "Overfitting and spending your data",
    "section": "Data: forested\n",
    "text": "Data: forested\n\n\nnames(forested)\n\n [1] \"forested\"         \"year\"            \n [3] \"elevation\"        \"eastness\"        \n [5] \"northness\"        \"roughness\"       \n [7] \"tree_no_tree\"     \"dew_temp\"        \n [9] \"precip_annual\"    \"temp_annual_mean\"\n[11] \"temp_annual_min\"  \"temp_annual_max\" \n[13] \"temp_january_min\" \"vapor_min\"       \n[15] \"vapor_max\"        \"canopy_cover\"    \n[17] \"lon\"              \"lat\"             \n[19] \"land_type\""
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#outcome-and-predictors",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#outcome-and-predictors",
    "title": "Overfitting and spending your data",
    "section": "Outcome and predictors",
    "text": "Outcome and predictors\n\nOutcome: forested - Factor, Yes or No\n\n\n\nlevels(forested$forested)\n\n[1] \"Yes\" \"No\" \n\n\n\n\n\nPredictors: 18 remotely-sensed and easily-accessible variables:\n\nnumeric variables based on weather and topography\ncategorical variables based on classifications from other governmental organizations"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested",
    "title": "Overfitting and spending your data",
    "section": "?forested",
    "text": "?forested"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#should-we-include-a-predictor",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#should-we-include-a-predictor",
    "title": "Overfitting and spending your data",
    "section": "Should we include a predictor?",
    "text": "Should we include a predictor?\nTo determine whether we should include a predictor in a model, we should start by asking:\n\nIs it ethical to use this variable? (Or even legal?)\nWill this variable be available at prediction time?\nDoes this variable contribute to explainability?"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#weve-been-cheating",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#weve-been-cheating",
    "title": "Overfitting and spending your data",
    "section": "We’ve been cheating!",
    "text": "We’ve been cheating!\n\nSo far, we’ve been using all the data we have for building models. In predictive contexts, this would be considered cheating.\nEvaluating model performance for predicting outcomes that were used when building the models is like evaluating your learning with questions whose answers you’ve already seen."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#spending-your-data",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#spending-your-data",
    "title": "Overfitting and spending your data",
    "section": "Spending your data",
    "text": "Spending your data\nFor predictive models (used primarily in machine learning), we typically split data into training and test sets:\n\n\n\n\n\n\nThe training set is used to estimate model parameters.\nThe test set is used to find an independent assessment of model performance.\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nDo not use, or even peek at, the test set during training."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#how-much-to-spend",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#how-much-to-spend",
    "title": "Overfitting and spending your data",
    "section": "How much to spend?",
    "text": "How much to spend?\n\nThe more data we spend (use in training), the better estimates we’ll get.\nSpending too much data in training prevents us from computing a good assessment of predictive performance.\nSpending too much data in testing prevents us from computing a good estimate of model parameters."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-initial-split",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-initial-split",
    "title": "Overfitting and spending your data",
    "section": "The initial split",
    "text": "The initial split\nThe default split is 75% training, 25% testing.\n\nset.seed(20241112)\nforested_split &lt;- initial_split(forested)\nforested_split\n\n&lt;Training/Testing/Total&gt;\n&lt;5330/1777/7107&gt;"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#setting-a-seed",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#setting-a-seed",
    "title": "Overfitting and spending your data",
    "section": "Setting a seed",
    "text": "Setting a seed\n\n\n\nWhat does set.seed() do?\n\n\n\n\n\nTo create that split of the data, R generates “pseudo-random” numbers: while they are made to behave like random numbers, their generation is deterministic given a “seed”.\nThis allows us to reproduce results by setting that seed.\nWhich seed you pick doesn’t matter, as long as you don’t try a bunch of seeds and pick the one that gives you the best performance."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#accessing-the-data",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#accessing-the-data",
    "title": "Overfitting and spending your data",
    "section": "Accessing the data",
    "text": "Accessing the data\n\nforested_train &lt;- training(forested_split)\nforested_test &lt;- testing(forested_split)"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-training-set",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-training-set",
    "title": "Overfitting and spending your data",
    "section": "The training set",
    "text": "The training set\n\nforested_train\n\n# A tibble: 5,330 × 19\n   forested  year elevation eastness northness roughness\n   &lt;fct&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 Yes       2013       315      -17        98        92\n 2 No        2018       374       93       -34        23\n 3 No        2017       377       44       -89         1\n 4 Yes       2013       541       31       -94       139\n 5 Yes       2017       680       14       -98        20\n 6 Yes       2017      1482       76       -64        43\n 7 No        2020        84       42       -90        12\n 8 Yes       2011       210       34        93        16\n 9 No        2020       766       14        98        20\n10 Yes       2013      1559       98        16        79\n# ℹ 5,320 more rows\n# ℹ 13 more variables: tree_no_tree &lt;fct&gt;, dew_temp &lt;dbl&gt;,\n#   precip_annual &lt;dbl&gt;, temp_annual_mean &lt;dbl&gt;,\n#   temp_annual_min &lt;dbl&gt;, temp_annual_max &lt;dbl&gt;,\n#   temp_january_min &lt;dbl&gt;, vapor_min &lt;dbl&gt;,\n#   vapor_max &lt;dbl&gt;, canopy_cover &lt;dbl&gt;, lon &lt;dbl&gt;,\n#   lat &lt;dbl&gt;, land_type &lt;fct&gt;"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-testing-data",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#the-testing-data",
    "title": "Overfitting and spending your data",
    "section": "The testing data",
    "text": "The testing data\n\nforested_test\n\n🙈\n\n\ndim(forested_test)\n\n[1] 1777   19"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#initial-questions",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#initial-questions",
    "title": "Overfitting and spending your data",
    "section": "Initial questions",
    "text": "Initial questions\n\nWhat’s the distribution of the outcome, forested?\nWhat’s the distribution of numeric variables like precip_annual?\nHow does the distribution of forested differ across the categorical and numerical variables?\n\n\n\n\n\nWhich dataset should we use for the exploration? The entire data forested, the training data forested_train, or the testing data forested_test?"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-1",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-1",
    "title": "Overfitting and spending your data",
    "section": "forested",
    "text": "forested\n\n\n\nWhat’s the distribution of the outcome, forested?\n\n\n\n\n\nforested_train |&gt;\n  count(forested) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 2 × 3\n  forested     n     p\n  &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 Yes       2917 0.547\n2 No        2413 0.453"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#precip_annual",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#precip_annual",
    "title": "Overfitting and spending your data",
    "section": "precip_annual",
    "text": "precip_annual\nWhat’s the distribution of precip_annual?\n\nggplot(forested_train, aes(x = precip_annual)) +\n  geom_histogram(binwidth = 200)"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-precip_annual",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-precip_annual",
    "title": "Overfitting and spending your data",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"identity\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-precip_annual-1",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-precip_annual-1",
    "title": "Overfitting and spending your data",
    "section": "\nforested and precip_annual\n",
    "text": "forested and precip_annual\n\n\nggplot(\n  forested_train,\n  aes(x = precip_annual, fill = forested, group = forested)\n  ) +\n  geom_histogram(binwidth = 200, position = \"fill\", alpha = 0.7) +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-tree_no_tree",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-tree_no_tree",
    "title": "Overfitting and spending your data",
    "section": "\nforested and tree_no_tree\n",
    "text": "forested and tree_no_tree\n\n\nggplot(forested_train, aes(x = tree_no_tree, fill = forested)) +\n  geom_bar(position = \"fill\") +\n  scale_fill_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-lat-lon",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#forested-and-lat-lon",
    "title": "Overfitting and spending your data",
    "section": "\nforested and lat / lon\n",
    "text": "forested and lat / lon\n\n\nggplot(forested_train, aes(x = lon, y = lat, color = forested)) +\n  geom_point(alpha = 0.7) +\n  scale_color_manual(values = c(\"Yes\" = \"forestgreen\", \"No\" = \"gold2\")) +\n  theme_minimal()"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-false-negative-and-positive",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-false-negative-and-positive",
    "title": "Overfitting and spending your data",
    "section": "Recap: False negative and positive",
    "text": "Recap: False negative and positive\n\nFalse negative rate is the proportion of actual positives that were classified as negatives.\nFalse positive rate is the proportion of actual negatives that were classified as positives."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-sensitivity",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-sensitivity",
    "title": "Overfitting and spending your data",
    "section": "Recap: Sensitivity",
    "text": "Recap: Sensitivity\nSensitivity is the proportion of actual positives that were correctly classified as positive.\n\nAlso known as true positive rate and recall\nSensitivity = 1 − False negative rate\nUseful when false negatives are more “expensive” than false positives"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-specificity",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#recap-specificity",
    "title": "Overfitting and spending your data",
    "section": "Recap: Specificity",
    "text": "Recap: Specificity\nSpecificity is the proportion of actual negatives that were correctly classified as negative\n\nAlso known as true negative rate\nSpecificity = 1 − False positive rate"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#roc-curve",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#roc-curve",
    "title": "Overfitting and spending your data",
    "section": "ROC curve",
    "text": "ROC curve\nThe receiver operating characteristic (ROC) curve allows to assess the model performance across a range of thresholds."
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#roc-curve-1",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#roc-curve-1",
    "title": "Overfitting and spending your data",
    "section": "ROC curve",
    "text": "ROC curve\n\n\n\nWhich corner of the plot indicates the best model performance?"
  },
  {
    "objectID": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#next-steps-1",
    "href": "slides/3-2-2-overfitting-spending-data/3-2-2-overfitting-spending-data.html#next-steps-1",
    "title": "Overfitting and spending your data",
    "section": "Next steps",
    "text": "Next steps\n\nFit models on training data\nMake predictions on testing data\n\nEvaluate predictions on testing data:\n\nLinear models: R-squared, adjusted R-squared, RMSE (root mean squared error), etc.\nLogistic models: False negative and positive rates, AUC (area under the curve), etc.\n\n\nMake decisions based on model predictive performance, validity across various testing/training splits (aka “cross validation”), explainability"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#packages",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#packages",
    "title": "Linear regression with a categorical predictor",
    "section": "Packages",
    "text": "Packages\n\n\npalmerpenguins for data\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#data-penguins",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#data-penguins",
    "title": "Linear regression with a categorical predictor",
    "section": "Data: penguins\n",
    "text": "Data: penguins\n\nWe’ll work with the penguins dataset from the palmerpenguins package, which contains information on body measurements of three species of Antarctic penguins:\n\npenguins\n\n# A tibble: 344 × 7\n   species island    bill_length_mm bill_depth_mm\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;\n 1 Adelie  Torgersen           39.1          18.7\n 2 Adelie  Torgersen           39.5          17.4\n 3 Adelie  Torgersen           40.3          18  \n 4 Adelie  Torgersen           NA            NA  \n 5 Adelie  Torgersen           36.7          19.3\n 6 Adelie  Torgersen           39.3          20.6\n 7 Adelie  Torgersen           38.9          17.8\n 8 Adelie  Torgersen           39.2          19.6\n 9 Adelie  Torgersen           34.1          18.1\n10 Adelie  Torgersen           42            20.2\n# ℹ 334 more rows\n# ℹ 3 more variables: flipper_length_mm &lt;int&gt;,\n#   body_mass_g &lt;int&gt;, sex &lt;fct&gt;"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#variables",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#variables",
    "title": "Linear regression with a categorical predictor",
    "section": "Variables",
    "text": "Variables\n\nA researcher wants to study the relationship between body weights of penguins based on the island they were recorded on. How are the variables involved in this analysis different?\n\n\n\nOutcome: body weight (numerical)\nPredictor: island (categorical)"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#body-weight-vs.-island",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#body-weight-vs.-island",
    "title": "Linear regression with a categorical predictor",
    "section": "Body weight vs. island",
    "text": "Body weight vs. island\n\nDetermine whether each of the following plot types would be an appropriate choice for visualizing the relationship between body weight and island of penguins.\n\n\nScatterplot ❌\nBox plot ✅\nViolin plot ✅\nDensity plot ✅\nBar plot ❌\nStacked bar plot ❌"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#body-weight-vs.-island-1",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#body-weight-vs.-island-1",
    "title": "Linear regression with a categorical predictor",
    "section": "Body weight vs. island",
    "text": "Body weight vs. island\n\nggplot(\n  penguins, \n  aes(x = body_mass_g, y = island, color = island)\n  ) +\n  geom_boxplot(show.legend = FALSE)\n\nWarning: Removed 2 rows containing non-finite outside the scale\nrange (`stat_boxplot()`)."
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#fitting-the-model",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#fitting-the-model",
    "title": "Linear regression with a categorical predictor",
    "section": "Fitting the model",
    "text": "Fitting the model\n\nFit:\n\n\nbm_island_fit &lt;- linear_reg() |&gt;\n  fit(body_mass_g ~ island, data = penguins)\n\n\n\nTidy:\n\n\ntidy(bm_island_fit)\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#inspecting-the-model-output",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#inspecting-the-model-output",
    "title": "Linear regression with a categorical predictor",
    "section": "Inspecting the model output",
    "text": "Inspecting the model output\n\nWhy is Biscoe not on the output?\n\n\n\n# A tibble: 3 × 5\n  term            estimate std.error statistic   p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)        4716.      48.5      97.3 8.93e-250\n2 islandDream       -1003.      74.2     -13.5 1.42e- 33\n3 islandTorgersen   -1010.     100.      -10.1 4.66e- 21\n\n\n\n\nWhen fitting a model with a categorical predictor, the levels of the categorical predictor are encoded to dummy variables, except for one of the levels, the baseline level.\nIn this case Biscoe is the is the baseline level.\nEach slope coefficient describes the predicted difference between heights in that particular school compared to the baseline level."
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#dummy-variables",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#dummy-variables",
    "title": "Linear regression with a categorical predictor",
    "section": "Dummy variables",
    "text": "Dummy variables\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nisland\n\nDummy variable\n\n\n\nDream\nTorgersen\n\n\n\n\nBiscoe\n0\n0\n\n\nDream\n1\n0\n\n\ntorgersen\n0\n1\n\n\n\n\n\n\n\nFor a categorical predictor with \\(k\\) levels, we only need \\(k - 1\\) dummy variables to describe all of its levels:\n\n\nDream = 1 and Torgersen = 0, the penguin is from Dream island.\n\nDream = 0 and Torgersen = 1, the penguin is from Torgersen island.\n\nDream = 0 and Torgersen = 0, the penguin is from Biscoe island, we don’t need a third dummy variable to identify these penguins."
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#dummy-coding",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#dummy-coding",
    "title": "Linear regression with a categorical predictor",
    "section": "Dummy coding",
    "text": "Dummy coding\n\n\n\n\n\n\n\n\nNote\n\n\nYou do not need to do anything (i.e., write code) to do the “dummy coding”, R does this under the hood for you when you have a predictor that is categorical (a character or a factor)."
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#interpreting-the-model-output",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#interpreting-the-model-output",
    "title": "Linear regression with a categorical predictor",
    "section": "Interpreting the model output",
    "text": "Interpreting the model output\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\nIntercept: Penguins from Biscoe island are expected to weigh, on average, 4,716 grams.\nSlope - islandDream: Penguins from Dream island are expected to weigh, on average, 1,003 grams less than those from Biscoe island.\nSlope - islandTorgersen: Penguins from Torgersen island are expected to weigh, on average, 1,010 grams less than those from Biscoe island."
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#predicting-based-on-the-model",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#predicting-based-on-the-model",
    "title": "Linear regression with a categorical predictor",
    "section": "Predicting based on the model",
    "text": "Predicting based on the model\n\\[\n\\widehat{body~mass} = 4716 - 1003 \\times islandDream - 1010 \\times islandTorgersen\n\\]\n\n\nBiscoe: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 0 = 4716\\)\n\n\n\n\n\nDream: \\(\\widehat{body~mass} = 4716 - 1003 \\times 1 - 1010 \\times 0 = 3713\\)\n\n\n\n\n\nTorgersen: \\(\\widehat{body~mass} = 4716 - 1003 \\times 0 - 1010 \\times 1 = 3706\\)"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#predicting-based-on-the-model---again",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#predicting-based-on-the-model---again",
    "title": "Linear regression with a categorical predictor",
    "section": "Predicting based on the model - again",
    "text": "Predicting based on the model - again\n\nthree_penguins &lt;- tibble(\n  island = c(\"Biscoe\", \"Dream\", \"Torgersen\")\n  )\n\naugment(bm_island_fit, new_data = three_penguins)\n\n# A tibble: 3 × 2\n  .pred island   \n  &lt;dbl&gt; &lt;chr&gt;    \n1 4716. Biscoe   \n2 3713. Dream    \n3 3706. Torgersen"
  },
  {
    "objectID": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#models-with-categorical-predictors",
    "href": "slides/1-2-2-linear-regression-categorical-predictor/1-2-2-linear-model-categorical-predictor.html#models-with-categorical-predictors",
    "title": "Linear regression with a categorical predictor",
    "section": "Models with categorical predictors",
    "text": "Models with categorical predictors\n\nWhen the categorical predictor has many levels, they’re encoded to dummy variables.\nThe first level of the categorical variable is the baseline level. In a model with one categorical predictor, the intercept is the predicted value of the outcome for the baseline level (x = 0).\nEach slope coefficient describes the difference between the predicted value of the outcome for that level of the categorical variable compared to the baseline level."
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#packages",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#packages",
    "title": "Linear regression with a numerical predictor",
    "section": "Packages",
    "text": "Packages\n\n\nfivethirtyeight for data\n\ntidyverse for data wrangling and visualization\n\ntidymodels for modeling\n\n\nlibrary(fivethirtyeight)\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-prep",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-prep",
    "title": "Linear regression with a numerical predictor",
    "section": "Data prep",
    "text": "Data prep\n\nRename Rotten Tomatoes columns as critics and audience\n\nRename the dataset as movie_scores\n\n\n\nmovie_scores &lt;- fandango |&gt;\n  rename(\n    critics = rottentomatoes, \n    audience = rottentomatoes_user\n  )"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-overview",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-overview",
    "title": "Linear regression with a numerical predictor",
    "section": "Data overview",
    "text": "Data overview\n\nmovie_scores |&gt;\n  select(critics, audience)\n\n# A tibble: 146 × 2\n   critics audience\n     &lt;int&gt;    &lt;int&gt;\n 1      74       86\n 2      85       80\n 3      80       90\n 4      18       84\n 5      14       28\n 6      63       62\n 7      42       53\n 8      86       64\n 9      99       82\n10      89       87\n# ℹ 136 more rows"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-visualization",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#data-visualization",
    "title": "Linear regression with a numerical predictor",
    "section": "Data visualization",
    "text": "Data visualization"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#regression-model-1",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#regression-model-1",
    "title": "Linear regression with a numerical predictor",
    "section": "Regression model",
    "text": "Regression model\nA regression model is a function that describes the relationship between the outcome, \\(Y\\), and the predictor, \\(X\\).\n\\[\n\\begin{aligned}\nY &= \\color{black}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{black}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{black}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#regression-model-2",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#regression-model-2",
    "title": "Linear regression with a numerical predictor",
    "section": "Regression model",
    "text": "Regression model\n\n\n\\[\n\\begin{aligned}\nY &= \\color{#325b74}{\\textbf{Model}} + \\text{Error} \\\\[8pt]\n&= \\color{#325b74}{\\mathbf{f(X)}} + \\epsilon \\\\[8pt]\n&= \\color{#325b74}{\\boldsymbol{\\mu_{Y|X}}} + \\epsilon\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#simple-linear-regression",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#simple-linear-regression",
    "title": "Linear regression with a numerical predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\nUse simple linear regression to model the relationship between a numerical outcome (\\(Y\\)) and a single numerical predictor (\\(X\\)): \\[\\Large{Y = \\beta_0 + \\beta_1 X + \\epsilon}\\]\n\n\n\\(\\beta_1\\): True slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\beta_0\\): True intercept of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(\\epsilon\\): Error (residual)"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#simple-linear-regression-1",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#simple-linear-regression-1",
    "title": "Linear regression with a numerical predictor",
    "section": "Simple linear regression",
    "text": "Simple linear regression\n\\[\n\\Large{\\hat{Y} = b_0 + b_1 X}\n\\]\n\n\n\\(b_1\\): Estimated slope of the relationship between \\(X\\) and \\(Y\\)\n\n\n\\(b_0\\): Estimated intercept of the relationship between \\(X\\) and \\(Y\\)\n\nNo error term!"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#choosing-values-for-b_1-and-b_0",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#choosing-values-for-b_1-and-b_0",
    "title": "Linear regression with a numerical predictor",
    "section": "Choosing values for \\(b_1\\) and \\(b_0\\)\n",
    "text": "Choosing values for \\(b_1\\) and \\(b_0\\)"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#residuals",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#residuals",
    "title": "Linear regression with a numerical predictor",
    "section": "Residuals",
    "text": "Residuals\n\n\n\n\n\n\n\n\n\\[\n\\text{residual} = \\text{observed} - \\text{predicted} = y - \\hat{y}\n\\]"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#least-squares-line",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#least-squares-line",
    "title": "Linear regression with a numerical predictor",
    "section": "Least squares line",
    "text": "Least squares line\n\n\nThe residual for the \\(i^{th}\\) observation is\n\n\\[\ne_i = \\text{observed} - \\text{predicted} = y_i - \\hat{y}_i\n\\]\n\n\n\nThe sum of squared residuals is\n\n\\[\ne^2_1 + e^2_2 + \\dots + e^2_n\n\\]\n\n\n\nThe least squares line is the one that minimizes the sum of squared residuals"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#fitting-a-model",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#fitting-a-model",
    "title": "Linear regression with a numerical predictor",
    "section": "Fitting a model",
    "text": "Fitting a model\n\nmovies_fit &lt;- linear_reg() |&gt;\n  fit(audience ~ critics, data = movie_scores)\n\ntidy(movies_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic  p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)   32.3      2.34        13.8 4.03e-28\n2 critics        0.519    0.0345      15.0 2.70e-31"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-the-slope",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-the-slope",
    "title": "Linear regression with a numerical predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\nThe slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-the-slope-1",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-the-slope-1",
    "title": "Linear regression with a numerical predictor",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\nThe slope of the model for predicting audience score from critics score is 0.519. Which of the following is the best interpretation of this value?\n\n\n\n\nFor every one point increase in the critics score, the audience score goes up by 0.519 points, on average.\nFor every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\nFor every one point increase in the critics score, the audience score goes up by 0.519 points.\nFor every one point increase in the audience score, the critics score goes up by 0.519 points, on average."
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-slope-intercept",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#interpreting-slope-intercept",
    "title": "Linear regression with a numerical predictor",
    "section": "Interpreting slope & intercept",
    "text": "Interpreting slope & intercept\n\\[\n\\widehat{\\text{audience}} = 32.3 + 0.519 \\times \\text{critics}\n\\]\n\n\nSlope: For every one point increase in the critics score, we expect the audience score to be higher by 0.519 points, on average.\n\nIntercept: For movies with a critics score of 0, we expect the audience score to be 32.3 points, on average."
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#is-the-intercept-meaningful",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#is-the-intercept-meaningful",
    "title": "Linear regression with a numerical predictor",
    "section": "Is the intercept meaningful?",
    "text": "Is the intercept meaningful?\n✅ The intercept is meaningful in context of the data if\n\nthe predictor can feasibly take values equal to or near zero or\nthe predictor has values near zero in the observed data\n\n\n🛑 Otherwise, it might not be meaningful!"
  },
  {
    "objectID": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#least-squares-regression",
    "href": "slides/1-2-1-linear-regression-numerical-predictor/1-2-1-linear-model-numerical-predictor.html#least-squares-regression",
    "title": "Linear regression with a numerical predictor",
    "section": "Least squares regression",
    "text": "Least squares regression\nThe least squares regression line minimizes the sum of squares residuals. It has the following properties:\n\nGoes through the center of mass point (the coordinates corresponding to average \\(X\\) and average \\(Y\\)): \\(b_0 = \\bar{Y} - b_1~\\bar{X}\\)\nSlope of the line has the same sign as the correlation coefficient: \\(b_1 = r \\frac{s_Y}{s_X}\\)\nSum of the residuals is zero: \\(\\sum_{i = 1}^n \\epsilon_i = 0\\)\nResiduals and \\(X\\) values are uncorrelated"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html",
    "title": "Modeling fish",
    "section": "",
    "text": "Practice modeling using the fish dataset on two common fish species in fish market sales.\n\nWe will use the tidyverse package for data wrangling and visualization and the tidymodels package for modeling.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\n\nThese data come from Kaggle and is commonly used in machine learning examples.\n\nfish &lt;- read_csv(\"https://data-science-with-r.github.io/data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nLet’s take a look at the data.\n\nfish\n\n# A tibble: 55 × 7\n   species weight length_vertical length_diagonal length_cross height width\n   &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bream      242            23.2            25.4         30     11.5  4.02\n 2 Bream      290            24              26.3         31.2   12.5  4.31\n 3 Bream      340            23.9            26.5         31.1   12.4  4.70\n 4 Bream      363            26.3            29           33.5   12.7  4.46\n 5 Bream      430            26.5            29           34     12.4  5.13\n 6 Bream      450            26.8            29.7         34.7   13.6  4.93\n 7 Bream      500            26.8            29.7         34.5   14.2  5.28\n 8 Bream      390            27.6            30           35     12.7  4.69\n 9 Bream      450            27.6            30           35.1   14.0  4.84\n10 Bream      500            28.5            30.7         36.2   14.2  4.96\n# ℹ 45 more rows"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#goal",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#goal",
    "title": "Modeling fish",
    "section": "",
    "text": "Practice modeling using the fish dataset on two common fish species in fish market sales."
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#packages",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#packages",
    "title": "Modeling fish",
    "section": "",
    "text": "We will use the tidyverse package for data wrangling and visualization and the tidymodels package for modeling.\n\nlibrary(tidyverse)\nlibrary(tidymodels)"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#data",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#data",
    "title": "Modeling fish",
    "section": "",
    "text": "These data come from Kaggle and is commonly used in machine learning examples.\n\nfish &lt;- read_csv(\"https://data-science-with-r.github.io/data/fish.csv\")\n\nThe data dictionary is below:\n\n\nvariable\ndescription\n\n\n\nspecies\nSpecies name of fish\n\n\nweight\nWeight, in grams\n\n\nlength_vertical\nVertical length, in cm\n\n\nlength_diagonal\nDiagonal length, in cm\n\n\nlength_cross\nCross length, in cm\n\n\nheight\nHeight, in cm\n\n\nwidth\nDiagonal width, in cm\n\n\n\nLet’s take a look at the data.\n\nfish\n\n# A tibble: 55 × 7\n   species weight length_vertical length_diagonal length_cross height width\n   &lt;chr&gt;    &lt;dbl&gt;           &lt;dbl&gt;           &lt;dbl&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 Bream      242            23.2            25.4         30     11.5  4.02\n 2 Bream      290            24              26.3         31.2   12.5  4.31\n 3 Bream      340            23.9            26.5         31.1   12.4  4.70\n 4 Bream      363            26.3            29           33.5   12.7  4.46\n 5 Bream      430            26.5            29           34     12.4  5.13\n 6 Bream      450            26.8            29.7         34.7   13.6  4.93\n 7 Bream      500            26.8            29.7         34.5   14.2  5.28\n 8 Bream      390            27.6            30           35     12.7  4.69\n 9 Bream      450            27.6            30           35.1   14.0  4.84\n10 Bream      500            28.5            30.7         36.2   14.2  4.96\n# ℹ 45 more rows"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#visualizing-the-model",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#visualizing-the-model",
    "title": "Modeling fish",
    "section": "Visualizing the model",
    "text": "Visualizing the model\nWe’re going to investigate the relationship between the weights and heights of fish, predicting weight from height.\n\nCreate an appropriate plot to investigate this relationship. Add appropriate labels to the plot.\n\n\n# add code here\n\n\nIf you were to draw a a straight line to best represent the relationship between the heights and weights of fish, where would it go? Why?\n\nAdd response here.\n\nNow, let R draw the line for you! Hint: Use geom_smooth().\n\n\n# add code here\n\n\nWhat types of questions can this plot help answer?\n\nAdd response here.\n\nWe can use this line to make predictions. Predict what you think the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm. Which prediction is considered extrapolation?\n\nAdd response here.\n\nWhat is a residual?\n\nAdd response here."
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#model-fitting",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#model-fitting",
    "title": "Modeling fish",
    "section": "Model fitting",
    "text": "Model fitting\n\nFit a model to predict fish weights from their heights.\n\n\n# add code here\n\n\nPredict what the weight of a fish would be with a height of 10 cm, 15 cm, and 20 cm using this model.\n\n\n# add code here\n\n\nCalculate predicted weights for all fish in the data and visualize the residuals under this model.\n\n\n# add code here"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#model-summary",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#model-summary",
    "title": "Modeling fish",
    "section": "Model summary",
    "text": "Model summary\n\nDisplay the model summary including estimates for the slope and intercept along with measurements of uncertainty around them. Show how you can extract these values from the model output.\n\n\n# add code here\n\n\nWrite out your model using mathematical notation.\n\nAdd response here."
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#correlation",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#correlation",
    "title": "Modeling fish",
    "section": "Correlation",
    "text": "Correlation\nWe can also assess correlation between two quantitative variables.\n\nWhat is correlation? What are values correlation can take?\n\nAdd response here.\n\nAre you good at guessing correlation? Give it a try! https://www.rossmanchance.com/applets/2021/guesscorrelation/GuessCorrelation.html\nWhat is the correlation between heights and weights of fish?\n\n\n# add code here"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#adding-a-third-variable",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#adding-a-third-variable",
    "title": "Modeling fish",
    "section": "Adding a third variable",
    "text": "Adding a third variable\n\nDoes the relationship between heights and weights of fish change if we take into consideration species? Plot two separate straight lines for the Bream and Roach species.\n\n\n# add code here"
  },
  {
    "objectID": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#fitting-other-models",
    "href": "code-alongs/1-2-modeling-fish/1-2-modeling-fish.html#fitting-other-models",
    "title": "Modeling fish",
    "section": "Fitting other models",
    "text": "Fitting other models\n\nWe can fit more models than just a straight line. Use method = \"loess\". What is different from the plot created before?\n\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html",
    "title": "Building a spam filter",
    "section": "",
    "text": "In this code along, we will\nTo illustrate logistic regression, we will build a spam filter from email data.\nThe data come from incoming emails in David Diez’s (one of the authors of OpenIntro textbooks) Gmail account for the first three months of 2012. All personally identifiable information has been removed.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\nglimpse(email)\n\nRows: 3,921\nColumns: 21\n$ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 0, …\n$ sent_email   &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, …\n$ time         &lt;dttm&gt; 2012-01-01 01:16:41, 2012-01-01 02:03:59, 2012-01-01 11:…\n$ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ dollar       &lt;dbl&gt; 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, …\n$ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no, no, no, no, n…\n$ inherit      &lt;dbl&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     &lt;dbl&gt; 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ num_char     &lt;dbl&gt; 11.370, 10.504, 7.773, 13.256, 1.231, 1.091, 4.837, 7.421…\n$ line_breaks  &lt;int&gt; 202, 202, 192, 255, 29, 25, 193, 237, 69, 68, 25, 79, 191…\n$ format       &lt;fct&gt; 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, …\n$ re_subj      &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, …\n$ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, …\n$ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess &lt;dbl&gt; 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 10, 4, 10, 20, 0…\n$ number       &lt;fct&gt; big, small, small, small, none, none, big, small, small, …\nThe variables we’ll use in this analysis are\nGoal: Use the number of exclamation points in an email to predict whether or not it is spam."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#fit",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#fit",
    "title": "Building a spam filter",
    "section": "Fit",
    "text": "Fit\nFit a linear regression model to whether an email is spam from the number of exclamation points in the email.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#visualize",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#visualize",
    "title": "Building a spam filter",
    "section": "Visualize",
    "text": "Visualize\nVisualizate the linear model.\n\n# add code here\n\n\nIs the linear model a good fit for the data? Why or why not?\n\nAdd response here."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#fit-1",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#fit-1",
    "title": "Building a spam filter",
    "section": "Fit",
    "text": "Fit\nFit a logistic regression model to predict the probability an email is spam from the number of exclamation points in the email.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#summarize",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#summarize",
    "title": "Building a spam filter",
    "section": "Summarize",
    "text": "Summarize\nWrite the estimated model.\n\\[\\log\\Big(\\frac{p}{1-p}\\Big) = -2.27 - 0.000272 \\times exclaim\\_mess\\]"
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#think",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#think",
    "title": "Building a spam filter",
    "section": "Think",
    "text": "Think\nSuppose you are a data scientist working on a spam filter. You must determine how high the predicted probability must be before you think it would be reasonable to call it spam and put it in the junk folder (which the user is unlikely to check). What are some trade offs you would consider as you set the decision-making threshold?\nAdd response here."
  },
  {
    "objectID": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#do",
    "href": "code-alongs/3-1-building-a-spam-filter/3-1-building-a-spam-filter.html#do",
    "title": "Building a spam filter",
    "section": "Do",
    "text": "Do\nClassify the emails in this dataset as spam or not spam.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html",
    "title": "Forest classification",
    "section": "",
    "text": "In this code along, we will\nWe will use tidyverse and tidymodels for data exploration and modeling, respectively, and the forested package for the data.\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(forested)\nRemember from the video that the forested dataset contains information on whether a plot is forested (Yes) or not (No) as well as numerical and categorical features of that plot.\nglimpse(forested)\n\nRows: 7,107\nColumns: 19\n$ forested         &lt;fct&gt; Yes, Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes,…\n$ year             &lt;dbl&gt; 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005, 2005,…\n$ elevation        &lt;dbl&gt; 881, 113, 164, 299, 806, 736, 636, 224, 52, 2240, 104…\n$ eastness         &lt;dbl&gt; 90, -25, -84, 93, 47, -27, -48, -65, -62, -67, 96, -4…\n$ northness        &lt;dbl&gt; 43, 96, 53, 34, -88, -96, 87, -75, 78, -74, -26, 86, …\n$ roughness        &lt;dbl&gt; 63, 30, 13, 6, 35, 53, 3, 9, 42, 99, 51, 190, 95, 212…\n$ tree_no_tree     &lt;fct&gt; Tree, Tree, Tree, No tree, Tree, Tree, No tree, Tree,…\n$ dew_temp         &lt;dbl&gt; 0.04, 6.40, 6.06, 4.43, 1.06, 1.35, 1.42, 6.39, 6.50,…\n$ precip_annual    &lt;dbl&gt; 466, 1710, 1297, 2545, 609, 539, 702, 1195, 1312, 103…\n$ temp_annual_mean &lt;dbl&gt; 6.42, 10.64, 10.07, 9.86, 7.72, 7.89, 7.61, 10.45, 10…\n$ temp_annual_min  &lt;dbl&gt; -8.32, 1.40, 0.19, -1.20, -5.98, -6.00, -5.76, 1.11, …\n$ temp_annual_max  &lt;dbl&gt; 12.91, 15.84, 14.42, 15.78, 13.84, 14.66, 14.23, 15.3…\n$ temp_january_min &lt;dbl&gt; -0.08, 5.44, 5.72, 3.95, 1.60, 1.12, 0.99, 5.54, 6.20…\n$ vapor_min        &lt;dbl&gt; 78, 34, 49, 67, 114, 67, 67, 31, 60, 79, 172, 162, 70…\n$ vapor_max        &lt;dbl&gt; 1194, 938, 754, 1164, 1254, 1331, 1275, 944, 892, 549…\n$ canopy_cover     &lt;dbl&gt; 50, 79, 47, 42, 59, 36, 14, 27, 82, 12, 74, 66, 83, 6…\n$ lon              &lt;dbl&gt; -118.6865, -123.0825, -122.3468, -121.9144, -117.8841…\n$ lat              &lt;dbl&gt; 48.69537, 47.07991, 48.77132, 45.80776, 48.07396, 48.…\n$ land_type        &lt;fct&gt; Tree, Tree, Tree, Tree, Tree, Tree, Non-tree vegetati…"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#fit",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#fit",
    "title": "Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on a subset of predictors of your choice. Name the model forested_custom_fit and display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#predict",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#predict",
    "title": "Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#evaluate",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#evaluate",
    "title": "Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\n# add code here\n\nAnother commonly used display of this information is a confusion matrix. Create this using the conf_mat() function. You will need to review the documentation for the function to determine how to use it.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#sensitivity-specificity-roc-curve",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#sensitivity-specificity-roc-curve",
    "title": "Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#fit-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#fit-1",
    "title": "Forest classification",
    "section": "Fit",
    "text": "Fit\nFit a model for classifying plots as forested or not based on all predictors available. Name the model forested_full_fit and display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#predict-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#predict-1",
    "title": "Forest classification",
    "section": "Predict",
    "text": "Predict\nPredict for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#evaluate-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#evaluate-1",
    "title": "Forest classification",
    "section": "Evaluate",
    "text": "Evaluate\nCalculate the false positive and false negative rates for the testing data using this model.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "href": "code-alongs/3-2-forest-classification/3-2-forest-classification.html#sensitivity-specificity-roc-curve-1",
    "title": "Forest classification",
    "section": "Sensitivity, specificity, ROC curve",
    "text": "Sensitivity, specificity, ROC curve\nCalculate sensitivity and specificity and draw the ROC curve.\n\n# add code here"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html",
    "title": "Modeling loan interest rates (Complete)",
    "section": "",
    "text": "Practice modeling with multiple predictors using the data on loan interest rates.\n\nThe dataset is about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n\n\nBefore we use the dataset, we’ll make a few transformations to it.\n\nReview the code below with your neighbor and write a summary of the data transformation pipeline.\n\nAdd response here.\n\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\n\nHere is a glimpse at the data:\n\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#goal",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#goal",
    "title": "Modeling loan interest rates (Complete)",
    "section": "",
    "text": "Practice modeling with multiple predictors using the data on loan interest rates."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#packages",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#packages",
    "title": "Modeling loan interest rates (Complete)",
    "section": "",
    "text": "The dataset is about loans from the peer-to-peer lender, Lending Club, from the openintro package. We will use tidyverse and tidymodels for data exploration and modeling, respectively.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#data-prep",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#data-prep",
    "title": "Modeling loan interest rates (Complete)",
    "section": "",
    "text": "Before we use the dataset, we’ll make a few transformations to it.\n\nReview the code below with your neighbor and write a summary of the data transformation pipeline.\n\nAdd response here.\n\nloans &lt;- loans_full_schema |&gt;\n  mutate(\n    credit_util = total_credit_utilized / total_credit_limit,\n    bankruptcy = as.factor(if_else(public_record_bankrupt == 0, 0, 1)),\n    verified_income = droplevels(verified_income),\n    homeownership = str_to_title(homeownership),\n    homeownership = fct_relevel(homeownership, \"Rent\", \"Mortgage\", \"Own\")\n  ) |&gt;\n  rename(credit_checks = inquiries_last_12m) |&gt;\n  select(\n    interest_rate, loan_amount, verified_income, \n    debt_to_income, credit_util, bankruptcy, term, \n    credit_checks, issue_month, homeownership\n  )\n\nHere is a glimpse at the data:\n\nglimpse(loans)\n\nRows: 10,000\nColumns: 10\n$ interest_rate   &lt;dbl&gt; 14.07, 12.61, 17.09, 6.72, 14.07, 6.72, 13.59, 11.99, …\n$ loan_amount     &lt;int&gt; 28000, 5000, 2000, 21600, 23000, 5000, 24000, 20000, 2…\n$ verified_income &lt;fct&gt; Verified, Not Verified, Source Verified, Not Verified,…\n$ debt_to_income  &lt;dbl&gt; 18.01, 5.04, 21.15, 10.16, 57.96, 6.46, 23.66, 16.19, …\n$ credit_util     &lt;dbl&gt; 0.54759517, 0.15003472, 0.66134832, 0.19673228, 0.7549…\n$ bankruptcy      &lt;fct&gt; 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, …\n$ term            &lt;dbl&gt; 60, 36, 36, 36, 36, 36, 60, 60, 36, 36, 60, 60, 36, 60…\n$ credit_checks   &lt;int&gt; 6, 1, 4, 0, 7, 6, 1, 1, 3, 0, 4, 4, 8, 6, 0, 0, 4, 6, …\n$ issue_month     &lt;fct&gt; Mar-2018, Feb-2018, Feb-2018, Jan-2018, Mar-2018, Jan-…\n$ homeownership   &lt;fct&gt; Mortgage, Rent, Rent, Rent, Rent, Own, Mortgage, Mortg…"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#get-to-know-the-data",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#get-to-know-the-data",
    "title": "Modeling loan interest rates (Complete)",
    "section": "Get to know the data",
    "text": "Get to know the data\n\nWhat is a typical interest rate in this dataset? What are some attributes of a typical loan and a typical borrower. Give yourself no more than 5 minutes for this exploration and share 1-2 findings.\n\nggplot(loans, aes(x = interest_rate)) +\n  geom_histogram(binwidth = 1)\nggplot(loans, aes(x = loan_amount)) +\n  geom_histogram(binwidth = 5000)\nggplot(loans, aes(x = term)) +\n  geom_bar()\nggplot(loans, aes(x = issue_month)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nggplot(loans, aes(x = credit_util)) +\n  geom_histogram(binwidth = 0.1)\nggplot(loans, aes(x = verified_income)) +\n  geom_bar()\nggplot(loans, aes(x = debt_to_income)) +\n  geom_histogram(binwidth = 10)\nggplot(loans, aes(x = bankruptcy)) +\n  geom_bar()\nggplot(loans, aes(x = credit_checks)) +\n  geom_bar()\nggplot(loans, aes(x = homeownership)) +\n  geom_bar()"
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-credit-utilization",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-credit-utilization",
    "title": "Modeling loan interest rates (Complete)",
    "section": "Interest rate vs. credit utilization",
    "text": "Interest rate vs. credit utilization\n\nFor a regression model for predicting interest rate from credit utilization. Display the summary output.\n\n\nrate_util_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util, data = loans)\n\ntidy(rate_util_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)    10.5     0.0871     121.  0        \n2 credit_util     4.73    0.180       26.3 1.18e-147\n\n\n\nVisualize the model.\n\n\nggplot(loans, aes(x = credit_util, y = interest_rate)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\nInterpret the intercept and the slope.\n\nIntercept: Borrowers with 0 credit utilization are predicted, on average, to get an interest rate of 10.5%.\nSlope: For each additional point credit utilization is higher, interest rate is predicted to be higher, on average, by 4.73%."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-homeownership",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-homeownership",
    "title": "Modeling loan interest rates (Complete)",
    "section": "Interest rate vs. homeownership",
    "text": "Interest rate vs. homeownership\n\nFit a regression model for predicting interest rate from homeownership and display the summary output.\n\n\nrate_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ homeownership, data = loans)\n\ntidy(rate_home_fit)\n\n# A tibble: 3 × 5\n  term                  estimate std.error statistic  p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)             12.9      0.0803    161.   0       \n2 homeownershipMortgage   -0.866    0.108      -8.03 1.08e-15\n3 homeownershipOwn        -0.611    0.158      -3.88 1.06e- 4\n\n\n\n\nInterpret each coefficient in context of the problem.\n\nIntercept: Loan applicants who rent are predicted to receive an interest rate of 12.9%, on average.\n\nSlopes:\n\nThe model predicts that loan applicants who have a mortgage for their home receive 0.866% lower interest rate than those who rent their home, on average.\nThe model predicts that loan applicants who own their home receive 0.611% lower interest rate than those who rent their home, on average."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-credit-utilization-and-homeownership",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#interest-rate-vs.-credit-utilization-and-homeownership",
    "title": "Modeling loan interest rates (Complete)",
    "section": "Interest rate vs. credit utilization and homeownership",
    "text": "Interest rate vs. credit utilization and homeownership\nMain effects model\n\nFit a regression model to predict interest rate from credit utilization and homeownership, without an interaction effect between the two predictors. Display the summary output.\n\n\nrate_util_home_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util + homeownership, data = loans)\n\ntidy(rate_util_home_fit)\n\n# A tibble: 4 × 5\n  term                  estimate std.error statistic   p.value\n  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)              9.93      0.140    70.8   0        \n2 credit_util              5.34      0.207    25.7   2.20e-141\n3 homeownershipMortgage    0.696     0.121     5.76  8.71e-  9\n4 homeownershipOwn         0.128     0.155     0.827 4.08e-  1\n\n\n\nWrite the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.93 + 5.34 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.626 + 5.34 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.058 + 5.34 \\times credit~util\\)\n\n\n\nHow does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nThe same.\nInteraction effects model\n\nFit a regression model to predict interest rate from credit utilization and homeownership, with an interaction effect between the two predictors. Display the summary output.\n\n\nrate_util_home_int_fit &lt;- linear_reg() |&gt;\n  fit(interest_rate ~ credit_util * homeownership, data = loans)\n\ntidy(rate_util_home_int_fit)\n\n# A tibble: 6 × 5\n  term                              estimate std.error statistic  p.value\n  &lt;chr&gt;                                &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                          9.44      0.199     47.5  0       \n2 credit_util                          6.20      0.325     19.1  1.01e-79\n3 homeownershipMortgage                1.39      0.228      6.11 1.04e- 9\n4 homeownershipOwn                     0.697     0.316      2.20 2.75e- 2\n5 credit_util:homeownershipMortgage   -1.64      0.457     -3.58 3.49e- 4\n6 credit_util:homeownershipOwn        -1.06      0.590     -1.80 7.24e- 2\n\n\n\nWrite the estimated regression equation for loan applications from each of the homeownership groups separately.\n\nRent: \\(\\widehat{interest~rate} = 9.44 + 6.20 \\times credit~util\\)\n\nMortgage: \\(\\widehat{interest~rate} = 10.83 + 4.56 \\times credit~util\\)\n\nOwn: \\(\\widehat{interest~rate} = 10.137 + 5.14 \\times credit~util\\)\n\n\n\nHow does the model predict the interest rate to vary as credit utilization varies for loan applicants with different homeownership status. Are the rates the same or different?\n\nDifferent.\nChoosing a model\nRule of thumb: Occam’s Razor - Don’t over-complicate the situation! We prefer the simplest best model.\n\nDisplay model level summary statistics.\n\n\nglance(rate_util_home_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0682        0.0679  4.83      244. 1.25e-152     3 -29926. 59861. 59897.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(rate_util_home_int_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0694        0.0689  4.83      149. 4.79e-153     5 -29919. 59852. 59903.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nWhat is R-squared? What is adjusted R-squared?\n\nR-squared is the percent variability in the response that is explained by our model. (Can use when models have same number of variables for model selection)\nAdjusted R-squared is similar, but has a penalty for the number of variables in the model. (Should use for model selection when models have different numbers of variables).\n\nBased on the adjusted \\(R^2\\)s of these two models, which one do we prefer?\n\nThe interaction effects model, though just barely."
  },
  {
    "objectID": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#another-model-to-consider",
    "href": "code-alongs/2-2-modeling-loan-interest-rates/2-2-modeling-loan-interest-rates-complete.html#another-model-to-consider",
    "title": "Modeling loan interest rates (Complete)",
    "section": "Another model to consider",
    "text": "Another model to consider\n\nLet’s add one more model to the variable – issue month. Should we add this variable to the interaction effects model from earlier?\n\n\nlinear_reg() |&gt;\n  fit(interest_rate ~ credit_util * homeownership + issue_month, data = loans) |&gt;\n  glance()\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic   p.value    df  logLik    AIC    BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1    0.0694        0.0688  4.83      106. 5.62e-151     7 -29919. 59856. 59921.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\nNo, the adjusted R-squared goes down."
  },
  {
    "objectID": "slides/3-1-logistic-regression/3-1-logistic-regression.html#a-binary-outcome",
    "href": "slides/3-1-logistic-regression/3-1-logistic-regression.html#a-binary-outcome",
    "title": "Logistic regression",
    "section": "A binary outcome",
    "text": "A binary outcome\n\\[\ny =\n\\begin{cases}\n1 & &&\\text{eg. Yes, Win, True, Heads, Success}\\\\\n0 & &&\\text{eg. No, Lose, False, Tails, Failure}.\n\\end{cases}\n\\]"
  },
  {
    "objectID": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#sensitivity-and-specificity",
    "href": "slides/3-2-1-classification-decision-errors/3-2-1-classification-decision-errors.html#sensitivity-and-specificity",
    "title": "Clasification and decision errors",
    "section": "Sensitivity and specificity",
    "text": "Sensitivity and specificity\n\n\n\n\n\n\n\n\n\nEmail is spam\nEmail is not spam\n\n\n\n\nEmail labelled spam\nTrue positive\nFalse positive (Type 1 error)\n\n\nEmail labelled not spam\nFalse negative (Type 2 error)\nTrue negative\n\n\n\n\n\nSensitivity = P(Labelled spam | Email spam) = TP / (TP + FN)\n\nSensitivity = 1 − False negative rate\n\n\n\n\n\nSpecificity = P(Labelled not spam | Email not spam) = TN / (FP + TN)\n\nSpecificity = 1 − False positive rate\n\n\n\n\n\nIf you were designing a spam filter, would you want sensitivity and specificity to be high or low? What are the trade-offs associated with each decision?"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#packages",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#packages",
    "title": "Quantifying uncertainty",
    "section": "Packages",
    "text": "Packages\n\n\ntidyverse for data wrangling and visualization\n\nscales for better axis labels\n\ntidymodels for modeling\n\nopenintro for data\n\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#data",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#data",
    "title": "Quantifying uncertainty",
    "section": "Data",
    "text": "Data\n\nFamily income and gift aid data from a random sample of fifty students in the freshman class of Elmhurst College in Illinois, USA\nGift aid is financial aid that doesn’t need to be paid back, unlike loans"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#linear-model",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#linear-model",
    "title": "Quantifying uncertainty",
    "section": "Linear model",
    "text": "Linear model\n\n\n\nlinear_reg() |&gt;\n  fit(gift_aid ~ family_income, data = elmhurst) |&gt;\n  tidy()\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interpreting-the-slope",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interpreting-the-slope",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\n\n\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4\n\n\n\nFor each additional $1,000 of family income, we would expect students to receive a net difference of 1,000 * (-0.0431) = -$43.10 in aid on average, i.e. $43.10 less in gift aid, on average."
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "exactly $43.10 for all students at this school?!"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#statistical-inference",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#statistical-inference",
    "title": "Quantifying uncertainty",
    "section": "Statistical inference",
    "text": "Statistical inference\n… is the process of using sample data to make conclusions about the underlying population the sample came from"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#estimation",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#estimation",
    "title": "Quantifying uncertainty",
    "section": "Estimation",
    "text": "Estimation\nSo far we have done lots of estimation (mean, median, slope, etc.), i.e. - used data from samples to calculate sample statistics - which can then be used as estimates for population parameters"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-1",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-1",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-2",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-2",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#confidence-intervals-1",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#confidence-intervals-1",
    "title": "Quantifying uncertainty",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nA plausible range of values for the population parameter is a confidence interval.\n\nIn order to construct a confidence interval we need to quantify the variability of our sample statistic\nFor example, if we want to construct a confidence interval for a population slope, we need to come up with a plausible range of values around our observed sample slope\nThis range will depend on how precise and how accurate our sample mean is as an estimate of the population mean\nQuantifying this requires a measurement of how much we would expect the sample population to vary from sample to sample"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-3",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-3",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#quantifying-the-variability-of-slopes",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#quantifying-the-variability-of-slopes",
    "title": "Quantifying uncertainty",
    "section": "Quantifying the variability of slopes",
    "text": "Quantifying the variability of slopes\nWe can quantify the variability of sample statistics using\n\nsimulation: via bootstrapping (in this course)\n\nor\n\ntheory: via Central Limit Theorem (in future stat courses!)\n\n\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrapping-1",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrapping-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\n\n\n\n“pulling oneself up by one’s bootstraps”: accomplishing an impossible task without any outside help\n\nImpossible task: estimating a population parameter using data from only the given sample\n\nNote: Notion of saying something about a population parameter using only information from an observed sample is the crux of statistical inference\n\n\n\n🥾"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#observed-sample",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#observed-sample",
    "title": "Quantifying uncertainty",
    "section": "Observed sample",
    "text": "Observed sample"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-population",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-population",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap population",
    "text": "Bootstrap population\nGenerated assuming there are more students like the ones in the observed sample…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrapping-scheme",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrapping-scheme",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping scheme",
    "text": "Bootstrapping scheme\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample\nCalculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\nRepeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\nCalculate the bounds of the XX% confidence interval as the middle XX% of the bootstrap distribution"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-1",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1\n\nelmhurtst_boot_1 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-2",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-2",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2\n\nelmhurtst_boot_2 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-3",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-3",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3\n\nelmhurtst_boot_3 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-4",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-sample-4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4\n\nelmhurtst_boot_4 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-samples-1---4",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#bootstrap-samples-1---4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap samples 1 - 4",
    "text": "Bootstrap samples 1 - 4"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-5",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-5",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#many-many-samples",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#many-many-samples",
    "title": "Quantifying uncertainty",
    "section": "Many many samples…",
    "text": "Many many samples…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#slopes-of-bootstrap-samples",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#slopes-of-bootstrap-samples",
    "title": "Quantifying uncertainty",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#confidence-interval",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#confidence-interval",
    "title": "Quantifying uncertainty",
    "section": "95% confidence interval",
    "text": "95% confidence interval"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interpreting-the-slope-take-two",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interpreting-the-slope-take-two",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope, take two",
    "text": "Interpreting the slope, take two\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1  -0.0699  -0.0217\n\n\nWe are 95% confident that for each additional $1,000 of family income, we would expect students to receive $69.95 to $21.7 less in gift aid, on average."
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#gone-fishing",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#gone-fishing",
    "title": "Quantifying uncertainty",
    "section": "Gone fishing…",
    "text": "Gone fishing…\n\nIf you want to catch a fish, do you prefer a spear or a net?"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-4",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#section-4",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#spear-or-net",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#spear-or-net",
    "title": "Quantifying uncertainty",
    "section": "Spear or net?",
    "text": "Spear or net?\n\n\n\nIf you want to catch a fish, do you prefer a spear or a net?"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interval-or-point",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#interval-or-point",
    "title": "Quantifying uncertainty",
    "section": "Interval or point?",
    "text": "Interval or point?\n\n\n\nIf you want to estimate a population parameter, do you prefer to report a range of values the parameter might be in, or a single value?\n\n\n\n\n\n\nIf we report a point estimate, we probably won’t hit the exact population parameter\nIf we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#sample-to-sample",
    "href": "slides/4-1-1/4-1-1-quantifying-uncertainty.html#sample-to-sample",
    "title": "Quantifying uncertainty",
    "section": "Sample to sample…",
    "text": "Sample to sample…\n\n\n\nSuppose we split a classroom in half down the middle of the classroom and ask each student their heights. Then, we calculate the mean height of students on each side of the classroom. Would you expect these two means to be exactly equal, close but not equal, or wildly different?\n\n\n\nSuppose you randomly sample 50 students and 5 of them are left handed. If you were to take another random sample of 50 students, how many would you expect to be left handed? Would you be surprised if only 3 of them were left handed? Would you be surprised if 40 of them were left handed?"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#packages",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#packages",
    "title": "Quantifying uncertainty",
    "section": "Packages",
    "text": "Packages\n\n\ntidyverse for data wrangling and visualization\n\nscales for better axis labels\n\ntidymodels for modeling\n\nopenintro for data\n\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(tidymodels)\nlibrary(openintro)"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#data",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#data",
    "title": "Quantifying uncertainty",
    "section": "Data",
    "text": "Data\n\nFamily income and gift aid data from a random sample of fifty students in the freshman class of Elmhurst College in Illinois, USA\nGift aid is financial aid that doesn’t need to be paid back, unlike loans"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#linear-model",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#linear-model",
    "title": "Quantifying uncertainty",
    "section": "Linear model",
    "text": "Linear model\n\n\n\nlinear_reg() |&gt;\n  fit(gift_aid ~ family_income, data = elmhurst) |&gt;\n  tidy()\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interpreting-the-slope",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interpreting-the-slope",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope",
    "text": "Interpreting the slope\n\n\n\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4\n\n\n\nFor each additional $1,000 of family income, we would expect students to receive a net difference of 1,000 * (-0.0431) = -$43.10 in aid on average, i.e. $43.10 less in gift aid, on average."
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#section",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#section",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "exactly $43.10 for all students at this school?!"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#statistical-inference",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#statistical-inference",
    "title": "Quantifying uncertainty",
    "section": "Statistical inference",
    "text": "Statistical inference\n… is the process of using sample data to make conclusions about the underlying population the sample came from"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#estimation",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#estimation",
    "title": "Quantifying uncertainty",
    "section": "Estimation",
    "text": "Estimation\nSo far we have done lots of estimation (mean, median, slope, etc.), i.e. - used data from samples to calculate sample statistics - which can then be used as estimates for population parameters"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#spear-or-net",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#spear-or-net",
    "title": "Quantifying uncertainty",
    "section": "Spear or net?",
    "text": "Spear or net?\n\n\n\nIf you want to catch a fish, do you prefer a spear or a net?"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interval-or-point",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interval-or-point",
    "title": "Quantifying uncertainty",
    "section": "Interval or point?",
    "text": "Interval or point?\n\n\n\nIf you want to estimate a population parameter, do you prefer to report a range of values the parameter might be in, or a single value?\n\n\n\n\n\n\nIf we report a point estimate, we probably won’t hit the exact population parameter\nIf we report a range of plausible values we have a good shot at capturing the parameter"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#confidence-intervals-1",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#confidence-intervals-1",
    "title": "Quantifying uncertainty",
    "section": "Confidence intervals",
    "text": "Confidence intervals\nA plausible range of values for the population parameter is a confidence interval.\n\nIn order to construct a confidence interval we need to quantify the variability of our sample statistic\nFor example, if we want to construct a confidence interval for a population slope, we need to come up with a plausible range of values around our observed sample slope\nThis range will depend on how precise and how accurate our sample mean is as an estimate of the population mean\nQuantifying this requires a measurement of how much we would expect the sample population to vary from sample to sample"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#sample-to-sample",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#sample-to-sample",
    "title": "Quantifying uncertainty",
    "section": "Sample to sample…",
    "text": "Sample to sample…\n\n\n\nSuppose we split a classroom in half down the middle of the classroom and ask each student their heights. Then, we calculate the mean height of students on each side of the classroom. Would you expect these two means to be exactly equal, close but not equal, or wildly different?\n\n\n\nSuppose you randomly sample 50 students and 5 of them are left handed. If you were to take another random sample of 50 students, how many would you expect to be left handed? Would you be surprised if only 3 of them were left handed? Would you be surprised if 40 of them were left handed?"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#quantifying-the-variability-of-sample-statistics",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#quantifying-the-variability-of-sample-statistics",
    "title": "Quantifying uncertainty",
    "section": "Quantifying the variability of sample statistics",
    "text": "Quantifying the variability of sample statistics\nWe can quantify the variability of sample statistics using\n\nsimulation: via bootstrapping (in this course)\n\n\nor\n\ntheory: via Central Limit Theorem (in future stat courses!)\n\n\n\n\n\n# A tibble: 2 × 5\n  term          estimate std.error statistic  p.value\n  &lt;chr&gt;            &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)    24.3       1.29       18.8  8.28e-24\n2 family_income  -0.0431    0.0108     -3.98 2.29e- 4"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrapping-1",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrapping-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping",
    "text": "Bootstrapping\n\n\n\n\n“pulling oneself up by one’s bootstraps”: accomplishing an impossible task without any outside help\n\nImpossible task: estimating a population parameter using data from only the given sample\n\nNote: Notion of saying something about a population parameter using only information from an observed sample is the crux of statistical inference\n\n\n\n🥾"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#observed-sample",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#observed-sample",
    "title": "Quantifying uncertainty",
    "section": "Observed sample",
    "text": "Observed sample"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-population",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-population",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap population",
    "text": "Bootstrap population\nGenerated assuming there are more students like the ones in the observed sample…"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrapping-scheme",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrapping-scheme",
    "title": "Quantifying uncertainty",
    "section": "Bootstrapping scheme",
    "text": "Bootstrapping scheme\n\nTake a bootstrap sample - a random sample taken with replacement from the original sample, of the same size as the original sample\nCalculate the bootstrap statistic - a statistic such as mean, median, proportion, slope, etc. computed on the bootstrap samples\nRepeat steps (1) and (2) many times to create a bootstrap distribution - a distribution of bootstrap statistics\nCalculate the bounds of the XX% confidence interval as the middle XX% of the bootstrap distribution"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-1",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-1",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 1",
    "text": "Bootstrap sample 1\n\nelmhurtst_boot_1 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-2",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-2",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 2",
    "text": "Bootstrap sample 2\n\nelmhurtst_boot_2 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-3",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-3",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 3",
    "text": "Bootstrap sample 3\n\nelmhurtst_boot_3 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-4",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-sample-4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap sample 4",
    "text": "Bootstrap sample 4\n\nelmhurtst_boot_4 &lt;- elmhurst |&gt;\n  slice_sample(n = 50, replace = TRUE)"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-samples-1---4",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#bootstrap-samples-1---4",
    "title": "Quantifying uncertainty",
    "section": "Bootstrap samples 1 - 4",
    "text": "Bootstrap samples 1 - 4"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#section-1",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#section-1",
    "title": "Quantifying uncertainty",
    "section": "",
    "text": "we could keep going…"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#many-many-samples",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#many-many-samples",
    "title": "Quantifying uncertainty",
    "section": "Many many samples…",
    "text": "Many many samples…"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#slopes-of-bootstrap-samples",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#slopes-of-bootstrap-samples",
    "title": "Quantifying uncertainty",
    "section": "Slopes of bootstrap samples",
    "text": "Slopes of bootstrap samples"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#confidence-interval",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#confidence-interval",
    "title": "Quantifying uncertainty",
    "section": "95% confidence interval",
    "text": "95% confidence interval"
  },
  {
    "objectID": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interpreting-the-slope-take-two",
    "href": "slides/4-1-1-quantifying-uncertainty/4-1-1-quantifying-uncertainty.html#interpreting-the-slope-take-two",
    "title": "Quantifying uncertainty",
    "section": "Interpreting the slope, take two",
    "text": "Interpreting the slope, take two\n\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1  -0.0705  -0.0217\n\n\nWe are 95% confident that for each additional $1,000 of family income, we would expect students to receive $70.48 to $21.68 less in gift aid, on average."
  }
]